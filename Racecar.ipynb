{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 5.12: Racetrack (programming) Consider driving a race car around a turn\n",
    "like those shown in Figure 5.5. You want to go as fast as possible, but not so fast as\n",
    "to run off the track. In our simplified racetrack, the car is at one of a discrete set of\n",
    "grid positions, the cells in the diagram. The velocity is also discrete, a number of grid\n",
    "cells moved horizontally and vertically per time step. The actions are increments to the\n",
    "velocity components. Each may be changed by +1, -1, or 0 in each step, for a total of\n",
    "nine (3 x 3) actions. Both velocity components are restricted to be nonnegative and less\n",
    "than 5, and they cannot both be zero except at the starting line. Each episode begins\n",
    "in one of the randomly selected start states with both velocity components zero and\n",
    "ends when the car crosses the finish line. The rewards are -1 for each step until the car\n",
    "crosses the finish line. If the car hits the track boundary, it is moved back to a random\n",
    "position on the starting line, both velocity components are reduced to zero, and the episode continues. Before updating the car’s location at each time step, check to see if\n",
    "the projected path of the car intersects the track boundary. If it intersects the finish line,\n",
    "the episode ends; if it intersects anywhere else, the car is considered to have hit the track\n",
    "boundary and is sent back to the starting line. To make the task more challenging, with\n",
    "probability 0.1 at each time step the velocity increments are both zero, independently of\n",
    "the intended increments. Apply a Monte Carlo control method to this task to compute\n",
    "the optimal policy from each starting state. Exhibit several trajectories following the\n",
    "optimal policy (but turn the noise o↵ for these trajectories)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 36)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_track = np.loadtxt(\"C:\\\\Users\\\\Joe\\\\Desktop\\\\Tufts Fall 2022\\\\CS 138\\\\HW2\\\\Large Track.txt\")\n",
    "large_track.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "lt_starting_line = np.where(large_track[29] == 1)[0]\n",
    "\n",
    "lt_starting_line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_track = np.loadtxt(\"C:\\\\Users\\\\Joe\\\\Desktop\\\\Tufts Fall 2022\\\\CS 138\\\\HW2\\\\Small Track.txt\")\n",
    "small_track.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 5, 6, 7, 8], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "st_starting_line = np.where(small_track[31] == 1)[0]\n",
    "st_starting_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt_rows = large_track.shape[0]\n",
    "lt_columns = large_track.shape[1]\n",
    "st_rows = small_track.shape[0]\n",
    "st_columns = small_track.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = [[0,0],[0,1],[0,-1],[1,0],[1,1],[1,-1],[-1,0],[-1,1],[-1,-1]]\n",
    "num_of_actions = len(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vel_max = 4\n",
    "vel_min = 0\n",
    "vel_len = (vel_max-vel_min+1)\n",
    "vel_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are the Q-Frames for each track\n",
    "\n",
    "large_Q = np.zeros(lt_rows*lt_columns*vel_len*vel_len*num_of_actions).reshape(lt_rows,lt_columns,vel_len, vel_len,num_of_actions)\n",
    "small_Q = np.zeros(st_rows*st_columns*vel_len*vel_len*num_of_actions).reshape(st_rows,st_columns, vel_len, vel_len, num_of_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Track:\n",
    "\n",
    "    def __init__(self, track, step_penalty, oob_penalty, finish_reward):\n",
    "        self.track = track\n",
    "        self.shape = track.shape\n",
    "        self.step_penalty = step_penalty\n",
    "        self.oob_penalty = oob_penalty\n",
    "        self.finish_reward = finish_reward\n",
    "        self.rows = self.shape[0]\n",
    "        self.columns = self.shape[1]\n",
    "        self.starting_line = np.where(self.track[self.rows-1] == 1)[0]\n",
    "\n",
    "    def assign_starting_point(self):\n",
    "        rand_index = np.random.randint(0,len(self.starting_line))\n",
    "        starting_col = self.starting_line[rand_index]\n",
    "        return [self.rows-1, starting_col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_track = Track(large_track, -1, -5, 20)\n",
    "#step penalty -1, off-track -5, finish +20\n",
    "s_track = Track(small_track, -1, -5, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Car:\n",
    "\n",
    "    def __init__(self, epsilon, gamma,noise_ratio, allow_noise, episode_max, q_frame, avail_actions, vel_max, vel_min):\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "        self.epsilon_shrink = False\n",
    "        \n",
    "        self.gamma = gamma\n",
    "        self.allow_noise = allow_noise\n",
    "        self.noise_ratio = noise_ratio\n",
    "        self.vel_max = vel_max\n",
    "        self.vel_min = vel_min\n",
    "        self.vel_len = (vel_max-vel_min+1)\n",
    "        self.episode_max = episode_max\n",
    "        self.episode_count = 0\n",
    "        self.q = np.copy(q_frame) #this is a multi dimensional array for each x, y, xvel, y vel, action return\n",
    "        self.state_action_counts = q_frame*0 #this is the same but will just be counts for each one (for updating)\n",
    "        self.actions = avail_actions \n",
    "        self.velocity = [0,0] #x is velocity moving right, y is velocity moving up\n",
    "        self.position = [0,0] #so our velocity y will increment our pos x and our veloicty x will increment pos y\n",
    "        self.rewards = list() #list of lists for each episode\n",
    "        self.total_rewards = list()\n",
    "        self.actions_taken = list() #list of lists for each episode\n",
    "        self.velocities = list() #list of lists for each episode\n",
    "        self.positions_in = list() #list of lists for each episode\n",
    "        self.step_count_per_episode = list()\n",
    "        self.start_spots = list() # list of where we started on each one\n",
    "        self.victory_count = 0\n",
    "        self.converged_episodes = list()\n",
    "        self.last_short_rew = 0\n",
    "        self.last_long_rew = 0\n",
    "        self.can_end = False\n",
    "        self.unique_spots_started = list()\n",
    "       \n",
    "\n",
    "    def avg_short_rew(self):\n",
    "        if self.episode_count < 550:\n",
    "            pass\n",
    "        else:\n",
    "            self.last_short_rew = 0\n",
    "            for i in range(len(self.rewards)-300, len(self.rewards)):\n",
    "                self.last_short_rew += sum(self.rewards[i])\n",
    "            self.last_short_rew = self.last_short_rew/300\n",
    "\n",
    "\n",
    "    def avg_long_rew(self):\n",
    "        if self.episode_count < 2250:\n",
    "            pass\n",
    "        else:\n",
    "            self.last_long_rew = 0\n",
    "            for i in range(len(self.rewards)-2000, len(self.rewards)):\n",
    "                self.last_long_rew += sum(self.rewards[i])\n",
    "            self.last_long_rew = self.last_long_rew/2000\n",
    "        \n",
    "    def completion_check(self):\n",
    "        #minimum episode condition\n",
    "        #episode_count_check = (self.episode_count > 2500)\n",
    "\n",
    "        #if episode_count_check:\n",
    "            #self.epsilon = 0 ~~~~~~~~~~~~~  ~~(abs(self.last_50_rew/self.last_300_rew-1) < .01) ~~~~~~~(abs((self.victory_count/self.episode_count)/(1-self.epsilon)-1) < .01)\n",
    "            if  (abs((self.victory_count/self.episode_count)/(1-self.epsilon)-1) < .01)   or (self.episode_count == self.episode_max):\n",
    "                self.can_end = True\n",
    "            \n",
    "            '''\n",
    "            \n",
    "            all_reward_quantile = np.quantile(self.total_rewards, .75)\n",
    "            recent_reward_quantile = np.quantile(self.total_rewards[-50:len(self.total_rewards)], self.epsilon)\n",
    "\n",
    "            if recent_reward_quantile > all_reward_quantile:\n",
    "                self.can_end = True'''\n",
    "\n",
    "        \n",
    "            \n",
    "    \n",
    "    def generate_possible_actions(self):\n",
    "        x_vel = self.velocity[0]\n",
    "        y_vel = self.velocity[1]\n",
    "        x_possi = list()\n",
    "        y_possi = list()\n",
    "\n",
    "        #create a list of possible x accelerations\n",
    "        if x_vel == self.vel_min:\n",
    "            for i in range(0,len(self.actions)):\n",
    "                if (self.actions[i][0] >= 0) and (self.actions[i][0] not in x_possi):\n",
    "                    x_possi.append(self.actions[i][0])\n",
    "        elif x_vel == self.vel_max:\n",
    "            for i in range(0,len(self.actions)):\n",
    "                if (self.actions[i][0] <= 0) and (self.actions[i][0] not in x_possi):\n",
    "                    x_possi.append(self.actions[i][0])\n",
    "        elif x_vel in range(self.vel_min+1, self.vel_max):\n",
    "            for i in range(0,len(self.actions)):\n",
    "                if (self.actions[i][0] not in x_possi):\n",
    "                    x_possi.append(self.actions[i][0])\n",
    "        #create a list of possible y accelerations\n",
    "        if y_vel == self.vel_min:\n",
    "            for i in range(0,len(self.actions)):\n",
    "                if (self.actions[i][1] >= 0) and (self.actions[i][1] not in y_possi):\n",
    "                    y_possi.append(self.actions[i][1])\n",
    "        if y_vel == self.vel_max:\n",
    "            for i in range(0,len(self.actions)):\n",
    "                if (self.actions[i][1] <= 0) and (self.actions[i][1] not in y_possi):\n",
    "                    y_possi.append(self.actions[i][1])\n",
    "        elif y_vel in range(self.vel_min+1, self.vel_max):\n",
    "            for i in range(0,len(self.actions)):\n",
    "                if (self.actions[i][1] not in y_possi):\n",
    "                    y_possi.append(self.actions[i][1])\n",
    "\n",
    "        step_actions = list()\n",
    "        #combine them together into all possible actions\n",
    "        for x in x_possi:\n",
    "            for y in y_possi:\n",
    "                step_actions.append([x,y])\n",
    "        #caveat that you can't have 0,0 velocity unless you're at the starting line -- this will prevent us from reaching 0,0\n",
    "        if self.velocity == [1,0]:\n",
    "            step_actions.remove([-1,0])\n",
    "        elif self.velocity == [0,1]:\n",
    "            step_actions.remove([0,-1])\n",
    "        elif self.velocity == [1,1]:\n",
    "            step_actions.remove([-1,-1])\n",
    "        elif self.velocity == list([0,0]):\n",
    "            step_actions.remove([0,0])\n",
    "\n",
    "        return step_actions\n",
    "\n",
    "    def choose_action(self, step_actions):\n",
    "        '''if self.allow_noise:\n",
    "            cutoff = (self.noise_ratio)*10000           Comes down to interpretation of instructions, I revised my interpretation to be: car chooses action, records action, but 0,0 is what is done\n",
    "            roll = np.random.randint(1,10001)\n",
    "            if roll < cutoff:\n",
    "                action = list([0,0])\n",
    "                return action\n",
    "            else:\n",
    "                pass'''\n",
    "        cutoff = (1-self.epsilon)*10000\n",
    "        roll = np.random.randint(1,10001)\n",
    "        if roll <= cutoff: #take greedy action for that state\n",
    "            #we want to take the action in the q array with the highest value -- even if its 0 as long as its possible\n",
    "            #greedy_action = self.actions[greedy_action_index]\n",
    "            avail_indics = list()\n",
    "            for i in range(0,len(self.actions)):\n",
    "                if self.actions[i] in step_actions:\n",
    "                    avail_indics.append(i) #indicies of available actions given velocity these indicies correspond to the actions array with 9 values\n",
    "            #print('Avail indics', avail_indics)\n",
    "            #print(self.q[self.q[self.position[0], self.position[1], self.velocity[0],self.velocity[1], np.r_[avail_indics]]])\n",
    "            try:\n",
    "                avail_qas = self.q[self.position[0], self.position[1], self.velocity[0],self.velocity[1], np.r_[avail_indics]]\n",
    "                action_index = np.argmax(avail_qas)\n",
    "                max_indis =list()\n",
    "                for i in range(0,len(avail_qas)):\n",
    "                    if avail_qas[i] == avail_qas[action_index]:\n",
    "                        max_indis.append(i)\n",
    "                action_indind = np.random.randint(0,len(max_indis))\n",
    "                action_index = max_indis[action_indind]\n",
    "\n",
    "            #^this gives the index of the highest value in the Q table for that state subject to it being an avail_indics\n",
    "            except:\n",
    "                roll = 10000\n",
    "                #print('Failed to be Greedy')\n",
    "            else:\n",
    "                action = step_actions[action_index] #action_index is in terms of the step_actions index so best action is this\n",
    "                \n",
    "                return action\n",
    "        if roll > cutoff:\n",
    "            rand_act_index = np.random.randint(0,len(step_actions))\n",
    "            action = step_actions[rand_act_index]\n",
    "            #print('explore')\n",
    "            return action\n",
    "            #return this to a variable, and then store that value so we keep track of each action\n",
    "    \n",
    "\n",
    "    #this was my original policy -- the issue was that it did not break ties arbitrarily so we updated to the above. Results seemed identical but this is more fair maybe over longer horizons\n",
    "    '''def choose_action2(self, step_actions):\n",
    "        if self.allow_noise:\n",
    "            cutoff = (self.noise_ratio)*10000\n",
    "            roll = np.random.randint(1,10001)\n",
    "            if roll < cutoff:\n",
    "                action = list([0,0])\n",
    "                return action\n",
    "            else:\n",
    "                pass\n",
    "        cutoff = (1-self.epsilon)*10000\n",
    "        roll = np.random.randint(1,10001)\n",
    "        if roll <= cutoff: #take greedy action for that state\n",
    "            #we want to take the action in the q array with the highest value -- even if its 0 as long as its possible\n",
    "            #greedy_action = self.actions[greedy_action_index]\n",
    "            avail_indics = list()\n",
    "            for i in range(0,len(self.actions)):\n",
    "                if self.actions[i] in step_actions:\n",
    "                    avail_indics.append(i) #indicies of available actions given velocity these indicies correspond to the actions array with 9 values\n",
    "            #print('Avail indics', avail_indics)\n",
    "            #print(self.q[self.q[self.position[0], self.position[1], self.velocity[0],self.velocity[1], np.r_[avail_indics]]])\n",
    "            try:\n",
    "\n",
    "                action_index = np.argmax(self.q[self.position[0], self.position[1], self.velocity[0],self.velocity[1], np.r_[avail_indics]])\n",
    "                \n",
    "            #^this gives the index of the highest value in the Q table for that state subject to it being an avail_indics\n",
    "            except:\n",
    "                roll = 10000\n",
    "                #print('Failed to be Greedy')\n",
    "            else:\n",
    "                action = step_actions[action_index] #action_index is in terms of the step_actions index so best action is this\n",
    "                \n",
    "                return action\n",
    "        if roll > cutoff:\n",
    "            rand_act_index = np.random.randint(0,len(step_actions))\n",
    "            action = step_actions[rand_act_index]\n",
    "            #print('explore')\n",
    "            return action\n",
    "            #return this to a variable, and then store that value so we keep track of each action\n",
    "            '''\n",
    "    \n",
    "\n",
    "    def update_meta_lists(self, start_spot,list_of_rewards, list_of_actions, list_of_positions, list_of_velocities, step_count):\n",
    "        self.start_spots.append(start_spot)\n",
    "        self.rewards.append(list_of_rewards)\n",
    "        self.actions_taken.append(list_of_actions)\n",
    "        self.positions_in.append(list_of_positions)\n",
    "        self.velocities.append(list_of_velocities)\n",
    "        self.step_count_per_episode.append(step_count)\n",
    "        self.total_rewards.append(sum(list_of_rewards))\n",
    "        if start_spot[1] not in self.unique_spots_started:\n",
    "            self.unique_spots_started.append(start_spot[1])\n",
    "\n",
    "        #now we need to update our Q table\n",
    "\n",
    "        #generate returns\n",
    "        returns = list()\n",
    "        for i in range(len(list_of_rewards)-1, 0-1,-1):\n",
    "            if i == len(list_of_rewards)-1:\n",
    "                returns.append(list_of_rewards[i])\n",
    "            else:\n",
    "                g_return = list_of_rewards[i] + self.gamma*returns[len(returns)-1]\n",
    "                returns.append(g_return)\n",
    "        returns.reverse() #put them in same order as all other actions\n",
    "        #print(returns)\n",
    "\n",
    "        #now we need to add this into the q table. iterate through each state/action, icrement count and incrmeemnt average value\n",
    "        \n",
    "        \n",
    "        for i in range(0,len(list_of_rewards)):\n",
    "            index_of_action_taken = self.actions.index(list_of_actions[i])\n",
    "            self.state_action_counts[list_of_positions[i][0],list_of_positions[i][1], list_of_velocities[i][0], list_of_velocities[i][1], index_of_action_taken] += 1\n",
    "            n = self.state_action_counts[list_of_positions[i][0],list_of_positions[i][1], list_of_velocities[i][0], list_of_velocities[i][1], index_of_action_taken]\n",
    "            delta = (1/n)*(returns[i] -self.q[list_of_positions[i][0],list_of_positions[i][1], list_of_velocities[i][0], list_of_velocities[i][1], index_of_action_taken] )\n",
    "            \n",
    "            self.q[list_of_positions[i][0],list_of_positions[i][1], list_of_velocities[i][0], list_of_velocities[i][1], index_of_action_taken] += delta\n",
    "\n",
    "       \n",
    "        \n",
    "    def check_track_value(self,x,y,track):\n",
    "        value = track.track[x,y]\n",
    "        return value\n",
    "\n",
    "    \n",
    "    def check_oob(self,x_pos, y_pos, x_vel,y_vel,track):\n",
    "        #y veloicty increments x_pos negatively\n",
    "        #x veloicty increments y_pos positively\n",
    "        \n",
    "        if self.check_track_value(x_pos,y_pos+x_vel,track) == 0: #this is redundant but I was getting weird lines -- i figured out it was an issue with seaborn but im keeping this in bc compute4dayz\n",
    "            return True\n",
    "\n",
    "        for i in range(0,x_vel+1):\n",
    "            for j in range(0,y_vel+1):\n",
    "                 if self.check_track_value(x_pos-j, y_pos+i, track) == 0:\n",
    "                    return True\n",
    "    \n",
    "        return False\n",
    "\n",
    "        \n",
    "        #these return True if the path of the car crosses out of bounds where the car travels first diagonally, and then either horizontally or vertically\n",
    "\n",
    "\n",
    "    def check_finish(self,x_pos, y_pos, x_vel,y_vel,track):\n",
    "        #copy the same thing above but return true if it equals 2  #I ended up revising the above to be more accurate but this still worked fine\n",
    "        if x_vel == y_vel:\n",
    "            for i in range(0,x_vel+1):\n",
    "                if self.check_track_value(x_pos-i, y_pos+i,track) == 2:\n",
    "                    return True\n",
    "        if x_vel > y_vel:\n",
    "            for i in range(0,y_vel):\n",
    "                if self.check_track_value(x_pos-i, y_pos+i,track) == 2:\n",
    "                    return True\n",
    "            for j in range(y_vel+1,x_vel+1):\n",
    "                if self.check_track_value(x_pos-y_vel, y_pos+j,track) == 2:\n",
    "                    return True\n",
    "        if x_vel < y_vel:\n",
    "            for i in range(0,x_vel):\n",
    "                if self.check_track_value(x_pos-i,y_pos+i, track) == 2:\n",
    "                    return True\n",
    "            for j in range(x_vel+1,y_vel+1):\n",
    "                if self.check_track_value(x_pos-j, y_pos+x_vel, track) == 2:\n",
    "                    return True\n",
    "\n",
    "        else:\n",
    "            return False\n",
    " \n",
    "\n",
    "    def run_episode(self, start_spot, track):\n",
    "        ep_rewards = list()\n",
    "        ep_actions = list()\n",
    "        ep_positions = list()\n",
    "        ep_velocities = list()\n",
    "        step_count = 0         \n",
    "        racing = True\n",
    "        self.position = list(start_spot)\n",
    "        #print('starting spot', self.position)\n",
    "        self.velocity = list([0,0])\n",
    "        #print('startingspeed', self.velocity)\n",
    "        ep_positions.append(self.position)\n",
    "        ep_velocities.append(self.velocity)\n",
    "        \n",
    "        while racing:\n",
    "            step_actions = self.generate_possible_actions()\n",
    "            #print('possible actions', step_actions)\n",
    "            action = self.choose_action(step_actions)\n",
    "            #print('chosen action', action)\n",
    "            ep_actions.append(action)\n",
    "\n",
    "            if self.allow_noise:\n",
    "                cutoff = (self.noise_ratio)*10000           \n",
    "                roll = np.random.randint(1,10001)\n",
    "                if roll < cutoff:\n",
    "                    action = list([0,0])\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "            self.velocity[0] += action[0]\n",
    "            self.velocity[1] += action[1]\n",
    "            #print('New speed',self.velocity)\n",
    "            ep_velocities.append(list(self.velocity))\n",
    "            step_count += 1\n",
    "            \n",
    "            if ((self.position[0] > track.rows-1) or (self.position[0] < 0)) or ((self.position[1] > track.columns-1) or (self.position[1] < 0)):\n",
    "                #print('Fell off track')\n",
    "                reward = track.oob_penalty\n",
    "                ep_rewards.append(reward)\n",
    "                self.position[0] = self.position[0] - self.velocity[1]\n",
    "                self.position[1] = self.position[1] + self.velocity[0]\n",
    "                #print('New Position',self.position)\n",
    "                ep_positions.append(list(self.position))\n",
    "                racing = False\n",
    "                break\n",
    "        \n",
    "            elif self.check_finish(self.position[0], self.position[1], self.velocity[0], self.velocity[1], track):   \n",
    "                    reward = track.finish_reward\n",
    "                    ep_rewards.append(reward)\n",
    "                    self.position[0] = self.position[0] - self.velocity[1]\n",
    "                    self.position[1] = self.position[1] + self.velocity[0]\n",
    "                    #print('New Position',self.position)\n",
    "                    ep_positions.append(list(self.position))\n",
    "                    self.victory_count += 1\n",
    "                    racing = False\n",
    "                    break\n",
    "\n",
    "            elif self.check_oob(self.position[0], self.position[1], self.velocity[0], self.velocity[1], track):    \n",
    "                    reward = track.oob_penalty\n",
    "                    ep_rewards.append(reward)\n",
    "                    self.position[0] = self.position[0] - self.velocity[1]\n",
    "                    self.position[1] = self.position[1] + self.velocity[0]\n",
    "                    #print('New Position',self.position)\n",
    "                    ep_positions.append(list(self.position))\n",
    "                    racing = False   \n",
    "                    break\n",
    "\n",
    "            else:\n",
    "                    reward = track.step_penalty\n",
    "                    ep_rewards.append(reward)\n",
    "                    self.position[0] = self.position[0] - self.velocity[1]\n",
    "                    self.position[1] = self.position[1] + self.velocity[0]\n",
    "                    #print('New Position',self.position)\n",
    "                    ep_positions.append(list(self.position))\n",
    "                    #ep_velocities.append(self.velocity)\n",
    "                    #ep_positions.append(self.position)\n",
    "\n",
    "        ep_velocities[0] = [0,0] #for some reason i have to do these two things here otherwise i get crazy values in the first index\n",
    "        ep_positions[0] = start_spot\n",
    "\n",
    "        self.update_meta_lists(start_spot,ep_rewards, ep_actions, ep_positions, ep_velocities, step_count)\n",
    "        \n",
    "        self.episode_count += 1        \n",
    "        self.avg_short_rew()\n",
    "        self.avg_long_rew()\n",
    "        self.completion_check()\n",
    "\n",
    "\n",
    "       \n",
    "        \n",
    "\n",
    "\n",
    "    def let_me_take_the_wheel(self,start_spot, track ,epsiodes = 10): #the \"epsiodes\" actually doesn't get used\n",
    "        #very similar to our run episode method except it asks for human input instead of choosing on its own\n",
    "        ep_rewards = list()\n",
    "        ep_actions = list()\n",
    "        ep_positions = list()\n",
    "        ep_velocities = list()\n",
    "        step_count = 0         \n",
    "        racing = True\n",
    "        self.position = list(start_spot)\n",
    "        #print('starting spot', self.position)\n",
    "        self.velocity = list([0,0])\n",
    "        #print('startingspeed', self.velocity)\n",
    "        ep_positions.append(self.position)\n",
    "        ep_velocities.append(self.velocity)\n",
    "        print('You start at ', self.position)\n",
    "        print('Velocity is ', self.velocity)\n",
    "        print('First digit increments horitzonal movement, second increments vertical')\n",
    "        samp_grid = np.copy(track.track)\n",
    "\n",
    "        while racing:\n",
    "            print('Current Episode Count', self.episode_count)\n",
    "            samp_grid[self.position[0], self.position[1]] = 1 # we are going to mark where we are with a 9 (printing out a section of the array), so here we set our old spot back to 1\n",
    "            step_actions = self.generate_possible_actions()\n",
    "            print('Possible Actions: ', step_actions)\n",
    "            action = list()\n",
    "            x_action = int(input('What is your first/horizontal increment? '))\n",
    "            action.append(x_action)\n",
    "            y_action = int(input('What is your second/vertical increment? '))\n",
    "            action.append(y_action)\n",
    "            if action not in step_actions:\n",
    "                print('Your entry is invalid, try:')\n",
    "                print(self.choose_action(step_actions))\n",
    "                action = self.choose_action(step_actions) #skynet chooses for you\n",
    "                \n",
    "            ep_actions.append(action)\n",
    "            self.velocity[0] += action[0]\n",
    "            self.velocity[1] += action[1]\n",
    "            print('New speed',self.velocity)\n",
    "            ep_velocities.append(list(self.velocity))\n",
    "            step_count += 1\n",
    "\n",
    "            if ((self.position[0] > track.rows-1) or (self.position[0] < 0)) or ((self.position[1] > track.columns-1) or (self.position[1] < 0)):\n",
    "                \n",
    "                reward = track.oob_penalty\n",
    "                ep_rewards.append(reward)\n",
    "                print('You fell off the track')\n",
    "                self.position[0] = self.position[0] - self.velocity[1]\n",
    "                self.position[1] = self.position[1] + self.velocity[0]\n",
    "                #print('New Position',self.position)\n",
    "                ep_positions.append(list(self.position))\n",
    "                racing = False\n",
    "                break\n",
    "\n",
    "            elif self.check_finish(self.position[0], self.position[1], self.velocity[0],self.velocity[1],track):   #  .check_win_condition()\n",
    "                    reward = track.finish_reward\n",
    "                    ep_rewards.append(reward)\n",
    "                    print('You finished!')\n",
    "                    self.position[0] = self.position[0] - self.velocity[1]\n",
    "                    self.position[1] = self.position[1] + self.velocity[0]\n",
    "                    #print('New Position',self.position)\n",
    "                    ep_positions.append(list(self.position))\n",
    "                    self.victory_count += 1\n",
    "                    racing = False\n",
    "                    break\n",
    "                \n",
    "            elif self.check_oob(self.position[0], self.position[1], self.velocity[0],self.velocity[1],track):    \n",
    "                    reward = track.oob_penalty\n",
    "                    ep_rewards.append(reward)\n",
    "                    print('You went out of bounds')\n",
    "                    self.position[0] = self.position[0] - self.velocity[1]\n",
    "                    self.position[1] = self.position[1] + self.velocity[0]\n",
    "                    #print('New Position',self.position)\n",
    "                    ep_positions.append(list(self.position))\n",
    "                    #ep_velocities.append(self.velocity)\n",
    "                    #ep_positions.append(self.position)\n",
    "                    racing = False   \n",
    "                    break\n",
    "         \n",
    "            else:\n",
    "                    reward = track.step_penalty\n",
    "                    ep_rewards.append(reward)\n",
    "                    self.position[0] = self.position[0] - self.velocity[1]\n",
    "                    self.position[1] = self.position[1] + self.velocity[0]\n",
    "                    print('New Position',self.position)\n",
    "                    ep_positions.append(list(self.position))\n",
    "\n",
    "                    samp_grid[self.position[0], self.position[1]] = 9\n",
    "                    track_row_min_index = max(self.position[0]-3,0)\n",
    "                    track_row_max_index = min(self.position[0] + 3, track.rows)\n",
    "                    track_col_min_index = max(self.position[1]-3,0)\n",
    "                    track_col_max_index = min(self.position[1]+3, track.columns)\n",
    "\n",
    "                    print(samp_grid[track_row_min_index:track_row_max_index, track_col_min_index:track_col_max_index])\n",
    "\n",
    "\n",
    "\n",
    "        ep_velocities[0] = [0,0] #for some reason i have to do these two things here otherwise i get crazy values in the first index\n",
    "        ep_positions[0] = start_spot\n",
    "\n",
    "        self.update_meta_lists(start_spot,ep_rewards, ep_actions, ep_positions, ep_velocities, step_count)\n",
    "        \n",
    "        self.episode_count += 1    \n",
    "        self.avg_short_rew()\n",
    "        self.avg_long_rew()\n",
    "        self.completion_check()\n",
    "\n",
    "    def print_stats(self):\n",
    "        print('episode count', self.episode_count)\n",
    "        print('highest reward',max(self.total_rewards))\n",
    "        print('last short average',self.last_short_rew)\n",
    "\n",
    "        print('last long avg rew',self.last_long_rew)\n",
    "\n",
    "        print('last 50 quantile',np.quantile(self.total_rewards[-50:len(self.total_rewards)],.5))\n",
    "        print('total quantile', np.quantile(self.total_rewards,.75))\n",
    "\n",
    "        print('Victory Count',self.victory_count)\n",
    "        print('% Vicotry',self.victory_count/self.episode_count)\n",
    "        print('Diff from Epsilon', self.victory_count/self.episode_count/(1-self.epsilon)-1)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Building the first simulation on the large track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "racecar = Car(epsilon=.1, gamma= .5,noise_ratio=.1,allow_noise=True,episode_max = 250000, q_frame =large_Q, avail_actions= actions, vel_max= vel_max, vel_min = vel_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#below is creating the car for creating the human q-frame. It's commented out so that the q-frame isn't overriden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#my_car = Car(epsilon=.1, gamma= .5,noise_ratio=.1,allow_noise=True,episode_max = 250000, q_frame =large_Q, avail_actions= actions, vel_max= vel_max, vel_min = vel_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140734"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run our first racecar on the large track with noise\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "\n",
    "\n",
    "while racecar.can_end == False:\n",
    "    racecar.run_episode(l_track.assign_starting_point(), l_track)\n",
    "   \n",
    "    \n",
    "\n",
    "avg_rewards = list()\n",
    "for i in range(0,len(racecar.rewards)):\n",
    "    avg_rew = sum(racecar.rewards[i])\n",
    "    avg_rewards.append(avg_rew)\n",
    "\n",
    "avg_rewards = np.array(avg_rewards)\n",
    "\n",
    "racecar.episode_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You start at  [29, 5]\n",
      "Velocity is  [0, 0]\n",
      "First digit increments horitzonal movement, second increments vertical\n",
      "Current Episode Count 16\n",
      "Possible Actions:  [[0, 1], [1, 0], [1, 1]]\n",
      "New speed [1, 1]\n",
      "New Position [28, 6]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 16\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1]]\n",
      "New speed [2, 2]\n",
      "New Position [26, 8]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 16\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [2, 3]\n",
      "New Position [23, 10]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 16\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [3, 4]\n",
      "New Position [19, 13]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 16\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1], [-1, 0], [-1, -1]]\n",
      "New speed [3, 4]\n",
      "New Position [15, 16]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 16\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1], [-1, 0], [-1, -1]]\n",
      "New speed [3, 4]\n",
      "New Position [11, 19]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 16\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1], [-1, 0], [-1, -1]]\n",
      "New speed [4, 3]\n",
      "New Position [8, 23]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 16\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [4, 2]\n",
      "New Position [6, 27]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 16\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [4, 2]\n",
      "You finished!\n",
      "You start at  [29, 11]\n",
      "Velocity is  [0, 0]\n",
      "First digit increments horitzonal movement, second increments vertical\n",
      "Current Episode Count 17\n",
      "Possible Actions:  [[0, 1], [1, 0], [1, 1]]\n",
      "New speed [1, 1]\n",
      "New Position [28, 12]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 17\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1]]\n",
      "New speed [1, 2]\n",
      "New Position [26, 13]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 17\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [2, 3]\n",
      "New Position [23, 15]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 17\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [2, 4]\n",
      "New Position [19, 17]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 17\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1], [-1, 0], [-1, -1]]\n",
      "New speed [2, 4]\n",
      "New Position [15, 19]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 17\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1], [-1, 0], [-1, -1]]\n",
      "New speed [2, 4]\n",
      "New Position [11, 21]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]]\n",
      "Current Episode Count 17\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1], [-1, 0], [-1, -1]]\n",
      "New speed [3, 3]\n",
      "New Position [8, 24]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 17\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [4, 2]\n",
      "New Position [6, 28]\n",
      "[[1. 1. 1. 1. 1. 2.]\n",
      " [1. 1. 1. 1. 1. 2.]\n",
      " [1. 1. 1. 1. 1. 2.]\n",
      " [1. 1. 1. 9. 1. 2.]\n",
      " [1. 1. 1. 1. 1. 2.]\n",
      " [1. 1. 1. 1. 1. 2.]]\n",
      "Current Episode Count 17\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [4, 2]\n",
      "You finished!\n",
      "You start at  [29, 12]\n",
      "Velocity is  [0, 0]\n",
      "First digit increments horitzonal movement, second increments vertical\n",
      "Current Episode Count 18\n",
      "Possible Actions:  [[0, 1], [1, 0], [1, 1]]\n",
      "New speed [0, 1]\n",
      "New Position [28, 12]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 18\n",
      "Possible Actions:  [[0, 0], [0, 1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 2]\n",
      "New Position [26, 12]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 18\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [1, 3]\n",
      "New Position [23, 13]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 18\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [2, 4]\n",
      "New Position [19, 15]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 18\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1], [-1, 0], [-1, -1]]\n",
      "New speed [2, 4]\n",
      "New Position [15, 17]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 18\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1], [-1, 0], [-1, -1]]\n",
      "New speed [2, 4]\n",
      "New Position [11, 19]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 18\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1], [-1, 0], [-1, -1]]\n",
      "New speed [2, 3]\n",
      "New Position [8, 21]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 18\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [3, 2]\n",
      "New Position [6, 24]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 18\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [4, 1]\n",
      "New Position [5, 28]\n",
      "[[1. 1. 1. 1. 1. 2.]\n",
      " [1. 1. 1. 1. 1. 2.]\n",
      " [1. 1. 1. 1. 1. 2.]\n",
      " [1. 1. 1. 9. 1. 2.]\n",
      " [1. 1. 1. 1. 1. 2.]\n",
      " [1. 1. 1. 1. 1. 2.]]\n",
      "Current Episode Count 18\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [4, 1]\n",
      "You finished!\n",
      "You start at  [29, 8]\n",
      "Velocity is  [0, 0]\n",
      "First digit increments horitzonal movement, second increments vertical\n",
      "Current Episode Count 19\n",
      "Possible Actions:  [[0, 1], [1, 0], [1, 1]]\n",
      "New speed [1, 1]\n",
      "New Position [28, 9]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 19\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1]]\n",
      "New speed [2, 2]\n",
      "New Position [26, 11]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 19\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [2, 3]\n",
      "New Position [23, 13]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 19\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [2, 4]\n",
      "New Position [19, 15]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 19\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1], [-1, 0], [-1, -1]]\n",
      "New speed [2, 4]\n",
      "New Position [15, 17]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 19\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1], [-1, 0], [-1, -1]]\n",
      "New speed [2, 4]\n",
      "New Position [11, 19]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 19\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1], [-1, 0], [-1, -1]]\n",
      "New speed [3, 3]\n",
      "New Position [8, 22]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 19\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [4, 2]\n",
      "New Position [6, 26]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 19\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [4, 2]\n",
      "You finished!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nwhile my_car.can_end == False:\\n    my_car.run_episode(l_track.assign_starting_point(), l_track)\\n   \\n    \\n\\nmy_avg_rewards = list()\\nfor i in range(0,len(my_car.rewards)):\\n    my_avg_rew = sum(my_car.rewards[i])\\n    my_avg_rewards.append(my_avg_rew)\\n\\nmy_avg_rewards = np.array(my_avg_rewards)\\n'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generate human q values on the large track\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "while my_car.episode_count < 10:\n",
    "     my_car.let_me_take_the_wheel(l_track.assign_starting_point(), l_track)\n",
    "human_10_eps_frame = np.copy(my_car.q)\n",
    "\n",
    "while my_car.episode_count < 20:\n",
    "    my_car.let_me_take_the_wheel(l_track.assign_starting_point(), l_track)\n",
    "\n",
    "human_20_eps_frame = np.copy(my_car.q)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Episode Count 20\n",
      "Racecar Episode Count 140734\n"
     ]
    }
   ],
   "source": [
    "print('My Episode Count', my_car.episode_count)\n",
    "print('Racecar Episode Count', racecar.episode_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode count 140734\n",
      "highest reward 12\n",
      "last short average 8.113333333333333\n",
      "last long avg rew 7.9045\n",
      "quantile 9.0\n",
      "total quantile 11.0\n",
      "125394\n",
      "0.8910000426336209\n",
      "-0.009999952629310194\n"
     ]
    }
   ],
   "source": [
    "#these series of print statements ended up getting built in as a method\n",
    "\n",
    "print('episode count',racecar.episode_count)\n",
    "print('highest reward',max(racecar.total_rewards))\n",
    "print('last short average',racecar.last_short_rew)\n",
    "\n",
    "print('last long avg rew',racecar.last_long_rew)\n",
    "\n",
    "print('quantile',np.quantile(racecar.total_rewards[-50:len(racecar.total_rewards)],.5))\n",
    "print('total quantile', np.quantile(racecar.total_rewards,.75))\n",
    "\n",
    "print(racecar.victory_count)\n",
    "print(racecar.victory_count/racecar.episode_count)\n",
    "print(racecar.victory_count/racecar.episode_count/(1-racecar.epsilon)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'plotaxis = np.arange(1,len(avg_rewards)+1)\\n\\nplt.figure(figsize=(30,10))\\nsns.lineplot(x=plotaxis, y = avg_rewards)\\nplt.show;\\n'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''plotaxis = np.arange(1,len(avg_rewards)+1)\n",
    "\n",
    "plt.figure(figsize=(30,10))\n",
    "sns.lineplot(x=plotaxis, y = avg_rewards)\n",
    "plt.show;\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140734\n"
     ]
    }
   ],
   "source": [
    "#Creating Trajectories for the large track racecar with noise\n",
    "\n",
    "trajectories = list() #list of positions\n",
    "traj_actions = list() #list of all actions\n",
    "for start_spot in range(0,len(l_track.starting_line)):\n",
    "    path = list()\n",
    "    path_actions = list()\n",
    "    not_finished = True\n",
    "    position = list([l_track.rows-1,start_spot])\n",
    "    velocity = list([0,0])\n",
    "    path.append(list(position))\n",
    "    while not_finished:\n",
    "        if velocity != list([0,0]): #so everywhere except the starting line\n",
    "            mask = (racecar.q[position[0], position[1], velocity[0],velocity[1]] != 0)\n",
    "            sub_ind = np.argmax(racecar.q[position[0], position[1], velocity[0],velocity[1]][mask])\n",
    "            full_ind = np.arange(racecar.q.shape[4])[mask][sub_ind]\n",
    "            path_action = actions[full_ind] #this is the optimal action taken at this location\n",
    "        else: \n",
    "            mask = (racecar.q[position[0], position[1], velocity[0],velocity[1]] != 0)[1:9]\n",
    "            sub_ind = np.argmax(racecar.q[position[0], position[1], velocity[0],velocity[1]][1:9][mask])\n",
    "            full_ind = np.arange(racecar.q.shape[4]-1)[mask][sub_ind]\n",
    "            path_action = actions[full_ind+1] #this is the optimal action taken at this location\n",
    "        path_actions.append(list(path_action))\n",
    "        velocity[0] += path_action[0]\n",
    "        velocity[1] += path_action[1]\n",
    "        position[0] = max(position[0] - velocity[1],0)\n",
    "        position[1] += velocity[0]\n",
    "        path.append(list(position))\n",
    "        if (l_track.track[position[0], position[1]] == 2) or (position[0] < 0):\n",
    "            not_finished = False\n",
    "            break\n",
    "        \n",
    "    trajectories.append(list(path))\n",
    "    traj_actions.append(list(path_actions))\n",
    "\n",
    "print(len(racecar.rewards))\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 35.0)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD8CAYAAABuHP8oAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAZpElEQVR4nO3deZRU9Z338fe3N3boRroBoVlVEFDBbgEREYgLycw56iOaaFySUdsQzcSZJKM+c+aMScbMRKPOuBF13CaPa8AtalTCcpyoQRtk6QaVBkFoegGlWRRR4Pv8URdtO910dXdV37pVn9c5dbrq1q2qj/fAxx+/+t3b5u6IiEj0ZIUdQERE2kcFLiISUSpwEZGIUoGLiESUClxEJKJU4CIiEdVqgZtZVzN7y8xWmlmlmf082P6wmX1gZiuC2/ikpxURkS/lxLHPPmCmu+8xs1zgz2b2x+C5n7n7vOTFExGRlrRa4B4702dP8DA3uOnsHxGRkFk8Z2KaWTawDDgKuNvdrzOzh4GTiY3QFwLXu/u+Zl5bBpQB9OjRo2T06NGJSy8ikgGWLVu23d0Lm26Pq8C/3NksH3gG+BHwEVAL5AH3Aevd/ReHe31paamXl5e3IbaIiJjZMncvbbq9TatQ3L0BWAzMcvcaj9kHPARMTEhSERGJSzyrUAqDkTdm1g04A3jXzAYG2ww4B6hIXkwREWkqnlUoA4FHgnnwLOApd3/BzBaZWSFgwArgB8mLKSIiTcWzCmUVMKGZ7TOTkkhEROKiMzFFRCJKBS4iElEqcBGRiFKBi4hElApcRCSiVOAiIhGlAhcRiSgVuIhIRKnARUQiSgUuIhJRKnARkYhSgYuIRJQKXEQkolTgIiIRpQIXEYkoFbiISESpwEVEIkoFLiISUSpwEZGIUoGLiESUClxEJKJU4CIiEdVqgZtZVzN7y8xWmlmlmf082D7czJaaWZWZPWlmecmPKyIih8QzAt8HzHT3E4DxwCwzmwz8Grjd3Y8CdgCXJy2liIj8lVYL3GP2BA9zg5sDM4F5wfZHgHOSEVBERJoX1xy4mWWb2QqgHlgArAca3H1/sMsWYFALry0zs3IzK9+2bVsCIouICMRZ4O5+wN3HA4OBicDoeD/A3e9z91J3Ly0sLGxfShER+SttWoXi7g3AYuBkIN/McoKnBgPViY0mIiKHE88qlEIzyw/udwPOANYSK/LZwW6XAc8lKaOIiDQjp/VdGAg8YmbZxAr/KXd/wczWAE+Y2b8B7wAPJDGniIg00WqBu/sqYEIz2zcQmw8XEZEQ6ExMEZGIUoFLQtXt+izsCCIZQwUuCVW/a1/YEUQyhgpcRCSiVOAiIhGlAhcRiSgVuIhIRKnAJaHcPewIIhkjnjMxRVq1/8BBLn5gKSP69eT44vyw44hkBI3AJSFysrM46PB61fawo4hkDBW4JMyssQPY9PGnbNi2p/WdRaTDVOCSMGeNGwDAK5V1IScRyQwqcEmYQfndOKqoJy9X1oYdRSQjqMAloaaMPIKVmxvY2rA37CgiaU8FLgk1ZUQ/AF7VKFwk6VTgklCDCrpxTH9No4h0BhW4JNyssQN464OP+WiPrkwokkwqcEm4s8YN4KDDgjVajSKSTCpwSbgxA3tT3LebplFEkkwFLglV1LsLZsassQN4vWo7uz77IuxIImlLBS4J1b93VwBmjRvAFwecxe/Wh5xIJH2pwCUpJhQXUNSrCy9XaBpFJFlaLXAzKzazxWa2xswqzezHwfYbzazazFYEt28lP65ERVaWcdbYASx5bxt7Pz8QdhyRtBTPCHw/8BN3HwNMBq42szHBc7e7+/jg9lLSUkokzRo3gL1fHOC1ddvCjiKSllotcHevcfflwf3dwFpgULKDSfRNHN6X/O65mkYRSZI2zYGb2TBgArA02HSNma0yswfNrKCF15SZWbmZlW/bppFYJsnNzuL0Y/vzp7V1fL7/YNhxRNJO3AVuZj2B+cC17r4LmAuMBMYDNcCtzb3O3e9z91J3Ly0sLOx4YomUWWMHsPuz/by54aOwo4iknbgK3MxyiZX3o+7+NIC717n7AXc/CNwPTExeTImqqUf3o3tetqZRRJIgnlUoBjwArHX32xptH9hot3OBisTHk6jrmpvNjNFFLFhTy4GD+oXHIokUzwj8FOASYGaTJYM3m9lqM1sFzAD+IZlBJbq+OW4A2/d8zrJNO8KOIpJWWv2t9O7+Z8CaeUrLBiUu00cVkZeTxcsVtUwc3jfsOCJpQ2diStL17JLDtKP78UplLe6aRhFJFBW4dIqzxg6gumEvFdW7wo4ikjZU4NIpTj+2P9lZxh8rasKOIpI2VODSKQp65DF5RF9ertA0ikiiqMCl08waO4AN2z+hqn5P2FFE0oIKXDrNmWMHAOikHpEEUYFLp+nfuyslQwt4SQUukhAqcOlUf3PcQNbW7OK92t1hRxGJPBW4dKqzxx9JTpYxf/mWsKOIRJ4KXDrVET27MHN0EU8vr2b/AV1iVqQjVODS6WaXDGb7nn36TT0iHaQCl043fVQRfXvkMW+ZplFEOkIFLp0uLyeLs8cfyZ/W1NPw6edhxxGJLBW4hGJ2yWA+P3CQP6zcGnYUkchSgUsoxh7Zh2MH9tY0ikgHqMAlNLNLBrNyy07er9OacJH2UIFLaL5cE65RuEi7qMAlNP16dmH6qCKeeUdrwkXaQwUuoZpdMpj63fv436rtYUcRiRwVuIRq5ugiCrrn6stMkXZQgUuoYmvCB7Ggso6dn34RdhyRSFGBS+gOrQl/fpXWhIu0RasFbmbFZrbYzNaYWaWZ/TjY3tfMFpjZuuBnQfLjSjoae2RvRg/opdUoIm0Uzwh8P/ATdx8DTAauNrMxwPXAQnc/GlgYPBZpMzNjdslgVmxuoKpea8JF4tVqgbt7jbsvD+7vBtYCg4CzgUeC3R4BzklSRskAZ48fRHaWMW9ZddhRRCKjTXPgZjYMmAAsBfq7e03wVC3QP7HRJJMU9urCjFGFPPPOFg4c1G+tF4lH3AVuZj2B+cC17r6r8XPu7kCzf+vMrMzMys2sfNs2Xf9ZWnbeiYOp27WPP2tNuEhc4ipwM8slVt6PuvvTweY6MxsYPD8QqG/ute5+n7uXuntpYWFhIjJLmpp5bBH5WhMuErd4VqEY8ACw1t1va/TU88Blwf3LgOcSH08ySZecbM4+4Uheqaxl516tCRdpTTwj8FOAS4CZZrYiuH0L+A/gDDNbB5wePBbpkNklxXy+/yAvaE24SKtyWtvB3f8MWAtPfyOxcSTTjRvUm2P692Tesi18d9LQsOOIpDSdiSkp5dCa8Hc+bGDZph1hxxFJaSpwSTnfPmkIg/K78fePv6Pro4gchgpcUk6fbrncddEE6nZ9xs/mrSS2SlVEmlKBS0qaMKSA6785mlfX1PHQ6xvDjiOSklTgkrIunzqc04/tz7//cS0rNzeEHUck5ajAJWWZGb85/3iKenXl6seWa224SBMqcElp+d3zuPOiCdTu/Ix/0ny4yNeowCXlnTikgOtmjeaVyjoefmNj2HFEUoYKXCLhilOHc/qxRfzqpbWs2tIQdhyRlKACl0iIzYefoPlwkUZU4BIZ+d3zuOPCCdQ0fMZ181ZpPlwyngpcIqVkaAH/NGsUL1fW8j9vbgo7jkioVOASOVdMHcHM0UXc9OJaVm/ZGXYckdCowCVysrKMW88/gSN65nH1Y8vZ9ZnmwyUzqcAlkgp65HHXRROobtjL9fM1Hy6ZSQUukVUytC8/O2sUL62u5Xd/0Xy4ZB4VuERa2akjmDGqkH97YS0V1ZoPl8yiApdIy8oybr1gvObDJSOpwCXy+vbI484LJ7Blx15umL9a8+GSMVTgkhZKh/Xlp2eO4sXVNfy/pR+GHUekU6jAJW1cNW0E00cV8ss/rNF8uGQEFbikjUPrw/v2yOOax5azW/PhkuZaLXAze9DM6s2sotG2G82s2sxWBLdvJTemSHyO6NmFOy+awOYde7nhac2HS3qLZwT+MDCrme23u/v44PZSYmOJtN9Jw/ryj2ccwwuranhU8+GSxlotcHd/Dfi4E7KIJMyc00Yy7ZhCfvHCGiq3aj5c0lNH5sCvMbNVwRRLQcISiSRAVpZx+wUnUNA9lyseKef9ut1hRxJJuPYW+FxgJDAeqAFubWlHMyszs3IzK9+2bVs7P06k7Y7o2YWHvjeRAwed2XPfYOmGj8KOJJJQ7Spwd69z9wPufhC4H5h4mH3vc/dSdy8tLCxsb06RdhlzZG/mz5lCYa8uXPLAW7y4qibsSCIJ064CN7OBjR6eC1S0tK9I2Ir7dmf+nCkcN7gP1zy+nIde/yDsSCIJEc8ywseBN4FRZrbFzC4Hbjaz1Wa2CpgB/EOSc4p0SH73PB69YhJnHNufn/9hDf/+0loOHtQSQ4m2nNZ2cPcLm9n8QBKyiCRV19xs5l5cwo3PV3Lvaxuo3fUZt8w+gbwcnc8m0dRqgYukk+ws4xdnj2VAn67c8sp7bN+zj99eXEKvrrlhRxNpMw09JOOYGVfPOIrfnH8CSzd8zAX3/oW6XZ+FHUukzVTgkrFmlwzmge+dxKaPPuH/3PMGVfVaKy7RogKXjHbaMYU8WXYy+/Yf5Ly5b1K+UScdS3SowCXjHTe4D0/PmULfHnl897+X8nJFbdiRROKiAhcBhhwRWyt+7MDezHl0Gb97c2PYkURapQIXCfTtkcfjV07mG6OL+JfnKrn55Xd1OVpJaSpwkUa65WXz24tLuHBiMfcsWc9Pfr+SLw4cDDuWSLO0DlykiZzsLH517nEM7NON2xa8z7bd+5h7cQk9u+ivi6QWjcBFmmFm/P03jubm847njfUf8e1736R+t9aKS2pRgYscxgUnFfPfl5ayYVtsrfiGbXvCjiTyJRW4SCtmjC7iibLJ7P38AOfNfYPlH+4IO5IIoAIXicsJxfnMnzOF3t1yuej+v7BgTV3YkURU4CLxGtavB/PnTOGY/r246nflPLp0U9iRJMOpwEXaoF/PLjx+5WSmHVPIPz9TwW2vvqe14hIaFbhIG/XoksP9l5ZyQelg7lhUxXXzV2mtuIRCC1tF2iE3O4tfn3c8A3p35Y5FVdTv3sfdF51ID60Vl06kEbhIO5kZ/3jmKH517nG89v42Lrz/L2zfsy/sWJJBVOAiHXTRpCHce0kp79ft5ry5b7Bea8Wlk6jARRLgjDH9efSKyeza+wVn3f4aNzy9is0ffxp2LElzKnCRBCkZWsDL107ju5OGMH9ZNTN+s4Qbnl7Nlh0qckkO68wlUKWlpV5eXt5pnycSlpqde5m7ZD1PvLUZx5ldUszVM0YyuKB72NEkgsxsmbuX/tV2FbhI8jQt8vNLi/nhdBW5tE27C9zMHgT+Fqh393HBtr7Ak8AwYCNwgbu3eoEIFbhkqq0NsSJ/8u2vivzqGUcxKL9b2NEkAloq8HjmwB8GZjXZdj2w0N2PBhYGj0WkBUfmd+OX54xjyc+m852ThjCvfAvTb1nMPz+zmuqGvWHHk4iKawrFzIYBLzQagb8HTHf3GjMbCCxx91GtvY9G4CIxWxv2cs+SKp58ezMAF5QW80ONyKUFHZoDb6bAG9w9P7hvwI5Dj5t5bRlQBjBkyJCSTZt0ASCRQ6ob9nLP4iqeKo8V+bdPKuaH04/iSBW5NJK0Ag8e73D3gtbeRyNwkeapyOVwOjIH3py6YOqE4Gd9R8KJZLpB+d246dzjWPzT6ZxfWsyTb29m+i1L+JdnK9iqOXJpQXsL/HngsuD+ZcBziYkjktkGF3TnV0GRzy4dzBNvf/hlkdfsVJHL18WzjPBxYDrQD6gD/hV4FngKGAJsIraM8OPWPkxTKCJts2XHp9y9eD2/L99MlhnfmVjMnOkjGdhHUyuZRCfyiETY5o8/5Z4lXxX5hROLmTP9KAb06Rp2NOkEKnCRNBAr8ip+X75FRZ5BVOAiaeRrRZ5lXDRxCD84baSKPE2pwEXS0OaPP+XuxVXMW/ZVkc+ZPpL+vVXk6UQFLpLGVOTpTQUukgE+/Cgo8uVbyFaRpw0VuEgGaVzkOVnGRZOGMOe0kRSpyCNJBS6SgT786FPuWryO+curVeQRpgIXyWBNi/y7k4byg9NGqMgjQgUuImz66BPuWlTF0++oyKNEBS4iX2pa5BdPHspVp42gqJeKPBWpwEXkr2zc/gl3La7iGRV5SlOBi0iLGhd5brZx8aShlKnIU4YKXERatXH7J9y5qIpn3tlCXk4WF08aylWnjaSwV5ewo2U0FbiIxO2D7bE58kNFfsnkoZRNU5GHRQUuIm2mIk8NKnARabcPtn/CnYvW8ew71eTlZHHpycMomzaCfj1V5J1BBS4iHda4yLvkZHPJyUNV5J1ABS4iCbNh2x7uWlTFsytiRX7pyUO5UkWeNCpwEUk4FXnnUIGLSNKsD4r8uUNFPmUoZaeO4AgVeUKowEUk6VTkyaECF5FOU1W/h7sWreP5lVvpmpvNpScP48pTh6vI2ykpBW5mG4HdwAFgf3Mf0JgKXCSzHCry51ZupZuKvN2SWeCl7r49nv1V4CKZqap+D3cGI/JDRV42bQR9e+SFHS0SVOAiErqq+t3cuajqyyK/bMowrjxVRd6aZBX4B8AOwIF73f2+ZvYpA8oAhgwZUrJp06Z2f56IpIeq+t3csbCKP6xSkccjWQU+yN2rzawIWAD8yN1fa2l/jcBFpLHGRd69UZEXqMi/JumrUMzsRmCPu/+mpX1U4CLSnHV1u7ljURUvBEX+vVOGccVUFfkhLRV4VgfesIeZ9Tp0HzgTqGh/RBHJVEf378WdF07glWunMWN0EfcsWc/UXy/illfeZccnn4cdL2W1ewRuZiOAZ4KHOcBj7n7T4V6jEbiIxOP9ut3csXAdL66uoUdeDt+bMowrTh1OfvfMHJHrRB4RiZz3andzx6J1vJThRa4CF5HIOlTkL66qoWeXHL5/yjAun5o5Ra4CF5HIe6/2q6mVTCpyFbiIpI13a3dx58IqXlxdQ68vi3wEfbrnhh0tKVTgIpJ23q3dxR0L1/HS6tq0LnIVuIikrbU1sSL/Y0VQ5FOHc/kpw9OmyFXgIpL20rXIVeAikjHWbI0V+cuVtfTqmsPfnTKcv5s6nD7dolnkKnARyTjpUuQqcBHJWJVbd3LHwnW8UllHr645XD51ON8/JTpFrgIXkYxXuXUn//Wndby6JlpFrgIXEQlUVMdG5K+uqaN31xwunzqC708dRu+uqVnkKnARkSYqqnfyXwvXsSDFizzhl5MVEYm6cYP6cP+lpbzwo6lMGnEEt//pfV5fF9dviEwJOWEHEBEJ26EiX1uzi1H9e4UdJ24qcBGRwLEDe4cdoU00hSIiElEqcBGRiFKBi4hElApcRCSiVOAiIhGlAhcRiSgVuIhIRHWowM1slpm9Z2ZVZnZ9okKJiEjr2l3gZpYN3A18ExgDXGhmYxIVTEREDq8jI/CJQJW7b3D3z4EngLMTE0tERFrTkVPpBwGbGz3eAkxqupOZlQFlwcN9ZlbRgc8MSz8gOle4+bqoZo9qbohu9qjmhuhmjzf30OY2Jv1aKO5+H3AfgJmVN3dJxFQX1dwQ3exRzQ3RzR7V3BDd7B3N3ZEplGqguNHjwcE2ERHpBB0p8LeBo81suJnlAd8Bnk9MLBERaU27p1Dcfb+ZXQO8AmQDD7p7ZSsvu6+9nxeyqOaG6GaPam6Ibvao5oboZu9Q7k79lWoiIpI4OhNTRCSiVOAiIhHVKQUe5VPuzWyjma02sxVmVh52nsMxswfNrL7xWnsz62tmC8xsXfCzIMyMzWkh941mVh0c9xVm9q0wMzbHzIrNbLGZrTGzSjP7cbA9Cse8pewpfdzNrKuZvWVmK4PcPw+2DzezpUHHPBksrEgph8n+sJl90OiYj4/7Td09qTdiX3CuB0YAecBKYEyyPzeB+TcC/cLOEWfWacCJQEWjbTcD1wf3rwd+HXbOOHPfCPw07Gyt5B4InBjc7wW8T+yyElE45i1lT+njDhjQM7ifCywFJgNPAd8Jtv8WmBN21jZkfxiY3Z737IwRuE657yTu/hrwcZPNZwOPBPcfAc7pzEzxaCF3ynP3GndfHtzfDawldoZyFI55S9lTmsfsCR7mBjcHZgLzgu2pesxbyt5unVHgzZ1yn/J/UBpx4FUzWxZcFiBq+rt7TXC/FugfZpg2usbMVgVTLCk3DdGYmQ0DJhAbVUXqmDfJDil+3M0s28xWAPXAAmL/wm9w9/3BLinbMU2zu/uhY35TcMxvN7Mu8b6fvsRs3VR3P5HYVRevNrNpYQdqL4/92y0q60bnAiOB8UANcGuoaQ7DzHoC84Fr3X1X4+dS/Zg3kz3lj7u7H3D38cTO/p4IjA43UfyaZjezccANxP4bTgL6AtfF+36dUeCRPuXe3auDn/XAM8T+wERJnZkNBAh+1oecJy7uXhf8YT8I3E+KHnczyyVWgI+6+9PB5kgc8+ayR+W4A7h7A7AYOBnIN7NDJyamfMc0yj4rmM5yd98HPEQbjnlnFHhkT7k3sx5m1uvQfeBMIGpXU3weuCy4fxnwXIhZ4naoAAPnkoLH3cwMeABY6+63NXoq5Y95S9lT/bibWaGZ5Qf3uwFnEJu/XwzMDnZL1WPeXPZ3G/3P3ojN3cd9zDvlTMxgKdJ/8tUp9zcl/UMTwMxGEBt1Q+yyA4+lcnYzexyYTuwSlXXAvwLPEvuGfgiwCbjA3VPqC8MWck8n9s94J7YS6KpG88opwcymAv8LrAYOBpv/L7G55FQ/5i1lv5AUPu5mdjyxLymziQ1An3L3XwR/V58gNgXxDnBxMKJNGYfJvggoJLZKZQXwg0Zfdh7+PTujwEVEJPH0JaaISESpwEVEIkoFLiISUSpwEZGIUoGLiESUClxEJKJU4CIiEfX/AQJ7ZgSNInq9AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_x_axis = list()\n",
    "test_y_axis = list()\n",
    "\n",
    "col = 13\n",
    "\n",
    "for i in range(0,len(trajectories[col])):\n",
    "    test_x_axis.append(trajectories[col][i][0])\n",
    "    test_y_axis.append(trajectories[col][i][1])\n",
    "\n",
    "test_x_axis=np.array(test_x_axis)\n",
    "test_y_axis=np.array(test_y_axis)\n",
    "\n",
    "sns.lineplot(x=test_y_axis, y=test_x_axis)\n",
    "plt.xlim([0,36])\n",
    "plt.ylim([0,35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(x=test_y_axis, y=test_x_axis, color = 'Red', lw =2, estimator=np.max)\n",
    "\n",
    "\n",
    "plt.imshow(large_track)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### now run a new racecar that uses my_car's q frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_car = Car(epsilon = .1, gamma = .5, noise_ratio=.1, allow_noise=True, episode_max= 250000, q_frame= human_20_eps_frame, avail_actions= actions, vel_max= vel_max, vel_min = vel_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_car.state_action_counts = my_car.state_action_counts * 10   # i want to give more weight to the human moves\n",
    "hybrid_car.episode_count = my_car.episode_count * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "\n",
    "\n",
    "while hybrid_car.can_end == False:\n",
    "    hybrid_car.run_episode(l_track.assign_starting_point(), l_track)\n",
    "   \n",
    "    \n",
    "\n",
    "hybrid_avg_rewards = list()\n",
    "for i in range(0,len(hybrid_car.rewards)):\n",
    "    hybrid_avg_rew = sum(hybrid_car.rewards[i])\n",
    "    hybrid_avg_rewards.append(hybrid_avg_rew)\n",
    "\n",
    "hybrid_avg_rewards = np.array(hybrid_avg_rewards)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode count 172505\n",
      "highest reward 12\n",
      "last short average 8.56\n",
      "last long avg rew 8.3065\n",
      "quantile 10.0\n",
      "total quantile 11.0\n",
      "Victory Count 153702\n",
      "0.891000260862004\n",
      "-0.0099997101533289\n"
     ]
    }
   ],
   "source": [
    "print('episode count',hybrid_car.episode_count)\n",
    "print('highest reward',max(hybrid_car.total_rewards))\n",
    "print('last short average',hybrid_car.last_short_rew)\n",
    "\n",
    "print('last long avg rew',hybrid_car.last_long_rew)\n",
    "\n",
    "print('quantile',np.quantile(hybrid_car.total_rewards[-50:len(hybrid_car.total_rewards)],.5))\n",
    "print('total quantile', np.quantile(hybrid_car.total_rewards,.75))\n",
    "\n",
    "print('Victory Count',hybrid_car.victory_count)\n",
    "print(hybrid_car.victory_count/hybrid_car.episode_count)\n",
    "print(hybrid_car.victory_count/hybrid_car.episode_count/(1-hybrid_car.epsilon)-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_hybrid_car = Car(epsilon = .1, gamma = .5, noise_ratio=.1, allow_noise=False, episode_max= 250000, q_frame= human_20_eps_frame, avail_actions= actions, vel_max= vel_max, vel_min = vel_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_hybrid_car.state_action_counts = my_car.state_action_counts * 10   # i want to give more weight to the human moves\n",
    "nn_hybrid_car.episode_count = my_car.episode_count * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "#while racecar.episode_count < 1:\n",
    " # racecar.let_me_take_the_wheel(l_track.assign_starting_point(), l_track)\n",
    "\n",
    "while nn_hybrid_car.can_end == False:\n",
    "    nn_hybrid_car.run_episode(l_track.assign_starting_point(), l_track)\n",
    "   \n",
    "    \n",
    "\n",
    "nn_hybrid_avg_rewards = list()\n",
    "for i in range(0,len(nn_hybrid_car.rewards)):\n",
    "    nn_hybrid_avg_rew = sum(nn_hybrid_car.rewards[i])\n",
    "    nn_hybrid_avg_rewards.append(nn_hybrid_avg_rew)\n",
    "\n",
    "nn_hybrid_avg_rewards = np.array(nn_hybrid_avg_rewards)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode count 70257\n",
      "highest reward 12\n",
      "last short average 9.526666666666667\n",
      "last long avg rew 9.26\n",
      "quantile 11.0\n",
      "total quantile 12.0\n",
      "62599\n",
      "0.8910001850349432\n",
      "-0.009999794405618712\n"
     ]
    }
   ],
   "source": [
    "print('episode count',nn_hybrid_car.episode_count)\n",
    "print('highest reward',max(nn_hybrid_car.total_rewards))\n",
    "print('last short average',nn_hybrid_car.last_short_rew)\n",
    "\n",
    "print('last long avg rew',nn_hybrid_car.last_long_rew)\n",
    "\n",
    "print('quantile',np.quantile(nn_hybrid_car.total_rewards[-50:len(nn_hybrid_car.total_rewards)],.5))\n",
    "print('total quantile', np.quantile(nn_hybrid_car.total_rewards,.75))\n",
    "\n",
    "print(nn_hybrid_car.victory_count)\n",
    "print(nn_hybrid_car.victory_count/nn_hybrid_car.episode_count)\n",
    "print(nn_hybrid_car.victory_count/nn_hybrid_car.episode_count/(1-nn_hybrid_car.epsilon)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_racecar = Car(epsilon = .1, gamma = .5, noise_ratio=.1, allow_noise=False, episode_max= 250000, q_frame= large_Q, avail_actions= actions, vel_max= vel_max, vel_min = vel_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "\n",
    "while nn_racecar.can_end == False:\n",
    "    nn_racecar.run_episode(l_track.assign_starting_point(), l_track)\n",
    "   \n",
    "    \n",
    "\n",
    "nn_avg_rewards = list()\n",
    "for i in range(0,len(nn_racecar.rewards)):\n",
    "    nn_avg_rew = sum(nn_racecar.rewards[i])\n",
    "    nn_avg_rewards.append(nn_avg_rew)\n",
    "\n",
    "nn_avg_rewards = np.array(nn_avg_rewards)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode count 68643\n",
      "highest reward 12\n",
      "last short average 9.08\n",
      "last long avg rew 9.0175\n",
      "quantile 10.0\n",
      "total quantile 11.0\n",
      "61161\n",
      "0.8910012674271229\n",
      "-0.009998591747641172\n"
     ]
    }
   ],
   "source": [
    "print('episode count',nn_racecar.episode_count)\n",
    "print('highest reward',max(nn_racecar.total_rewards))\n",
    "print('last short average',nn_racecar.last_short_rew)\n",
    "\n",
    "print('last long avg rew',nn_racecar.last_long_rew)\n",
    "\n",
    "print('quantile',np.quantile(nn_racecar.total_rewards[-50:len(nn_racecar.total_rewards)],.5))\n",
    "print('total quantile', np.quantile(nn_racecar.total_rewards,.75))\n",
    "\n",
    "print(nn_racecar.victory_count)\n",
    "print(nn_racecar.victory_count/nn_racecar.episode_count)\n",
    "print(nn_racecar.victory_count/nn_racecar.episode_count/(1-nn_racecar.epsilon)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Car_Type</th>\n",
       "      <th>Total_Episodes</th>\n",
       "      <th>Total_Finishes</th>\n",
       "      <th>Final_Victory_Pct</th>\n",
       "      <th>Last_50_Avg_Reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LT Racecar with Noise</td>\n",
       "      <td>140734</td>\n",
       "      <td>125394</td>\n",
       "      <td>0.891000</td>\n",
       "      <td>8.113333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LT Racecar with Noise and Human Boost</td>\n",
       "      <td>172505</td>\n",
       "      <td>153702</td>\n",
       "      <td>0.891000</td>\n",
       "      <td>8.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LT Racecar with No Noise</td>\n",
       "      <td>68643</td>\n",
       "      <td>61161</td>\n",
       "      <td>0.891001</td>\n",
       "      <td>9.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LT Racecar with No Noise and Human Boost</td>\n",
       "      <td>70257</td>\n",
       "      <td>62599</td>\n",
       "      <td>0.891000</td>\n",
       "      <td>9.526667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Car_Type  Total_Episodes  Total_Finishes  \\\n",
       "0                     LT Racecar with Noise          140734          125394   \n",
       "1     LT Racecar with Noise and Human Boost          172505          153702   \n",
       "2                  LT Racecar with No Noise           68643           61161   \n",
       "3  LT Racecar with No Noise and Human Boost           70257           62599   \n",
       "\n",
       "   Final_Victory_Pct  Last_50_Avg_Reward  \n",
       "0           0.891000            8.113333  \n",
       "1           0.891000            8.560000  \n",
       "2           0.891001            9.080000  \n",
       "3           0.891000            9.526667  "
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lt_car_meta_data = pd.DataFrame({\n",
    "    'Car_Type' : ['LT Racecar with Noise', 'LT Racecar with Noise and Human Boost', 'LT Racecar with No Noise','LT Racecar with No Noise and Human Boost'],\n",
    "    'Total_Episodes' : [racecar.episode_count, hybrid_car.episode_count, nn_racecar.episode_count, nn_hybrid_car.episode_count],\n",
    "    'Total_Finishes' : [racecar.victory_count, hybrid_car.victory_count, nn_racecar.victory_count, nn_hybrid_car.victory_count],\n",
    "    'Final_Victory_Pct' : [racecar.victory_count/racecar.episode_count, hybrid_car.victory_count/hybrid_car.episode_count, nn_racecar.victory_count/nn_racecar.episode_count, nn_hybrid_car.victory_count/nn_hybrid_car.episode_count],\n",
    "    'Last_50_Avg_Reward' : [racecar.last_short_rew, hybrid_car.last_short_rew, nn_racecar.last_short_rew, nn_hybrid_car.last_short_rew]\n",
    "})\n",
    "\n",
    "lt_car_meta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################~~~~~~~~~~ SMALL TRACK TIME ~~~~~~~~~~~~~~~~~############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_racecar = Car(epsilon = .1, gamma = .5, noise_ratio=.1, allow_noise=True, episode_max= 400000, q_frame= small_Q, avail_actions= actions, vel_max= vel_max, vel_min = vel_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "\n",
    "while small_racecar.can_end == False:\n",
    "    small_racecar.run_episode(s_track.assign_starting_point(), s_track)\n",
    "   \n",
    "    \n",
    "\n",
    "small_rc_avg_rews = list()\n",
    "for i in range(0,len(small_racecar.rewards)):\n",
    "    small_rc_avg_rew = sum(small_racecar.rewards[i])\n",
    "    small_rc_avg_rews.append(small_rc_avg_rew)\n",
    "\n",
    "small_rc_avg_rews = np.array(small_rc_avg_rews)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode count 400000\n",
      "highest reward 10\n",
      "last short average 0.13666666666666666\n",
      "last long avg rew 1.015\n",
      "quantile 6.5\n",
      "total quantile 8.0\n",
      "280344\n",
      "0.70086\n",
      "-0.2212666666666666\n"
     ]
    }
   ],
   "source": [
    "print('episode count',small_racecar.episode_count)\n",
    "print('highest reward',max(small_racecar.total_rewards))\n",
    "print('last short average',small_racecar.last_short_rew)\n",
    "\n",
    "print('last long avg rew',small_racecar.last_long_rew)\n",
    "\n",
    "print('quantile',np.quantile(small_racecar.total_rewards[-50:len(small_racecar.total_rewards)],.5))\n",
    "print('total quantile', np.quantile(small_racecar.total_rewards,.75))\n",
    "\n",
    "print(small_racecar.victory_count)\n",
    "print(small_racecar.victory_count/small_racecar.episode_count)\n",
    "print(small_racecar.victory_count/small_racecar.episode_count/(1-small_racecar.epsilon)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trajectories for the racecar on the small trak with noise\n",
    "\n",
    "small_trajectories = list() #list of positions\n",
    "small_traj_actions = list() #list of all actions\n",
    "for start_spot in range(min(s_track.starting_line),max(s_track.starting_line)+1):\n",
    "    path = list()\n",
    "    path_actions = list()\n",
    "    not_finished = True\n",
    "    position = list([s_track.rows-1,start_spot])\n",
    "    velocity = list([0,0])\n",
    "    path.append(list(position))\n",
    "    while not_finished:\n",
    "        if velocity != list([0,0]):\n",
    "            mask = (small_racecar.q[position[0], position[1], velocity[0],velocity[1]] != 0)\n",
    "            sub_ind = np.argmax(small_racecar.q[position[0], position[1], velocity[0],velocity[1]][mask])\n",
    "            full_ind = np.arange(small_racecar.q.shape[4])[mask][sub_ind]\n",
    "            path_action = actions[full_ind] #this is the optimal action taken at this location\n",
    "        else:\n",
    "            mask = (small_racecar.q[position[0], position[1], velocity[0],velocity[1]] != 0)[1:9]\n",
    "            sub_ind = np.argmax(small_racecar.q[position[0], position[1], velocity[0],velocity[1]][1:9][mask])\n",
    "            full_ind = np.arange(small_racecar.q.shape[4]-1)[mask][sub_ind]\n",
    "            path_action = actions[full_ind+1] #this is the optimal action taken at this location\n",
    "        path_actions.append(list(path_action))\n",
    "        velocity[0] += path_action[0]\n",
    "        velocity[1] += path_action[1]\n",
    "        position[0] = max(position[0] - velocity[1],0)\n",
    "        position[1] += velocity[0]\n",
    "        path.append(list(position))\n",
    "        if (s_track.track[position[0], position[1]] == 2) or (position[0] < 0):\n",
    "            not_finished = False\n",
    "            break\n",
    "        \n",
    "    small_trajectories.append(list(path))\n",
    "    small_traj_actions.append(list(path_actions))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 35.0)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_x_axis = list()\n",
    "test_y_axis = list()\n",
    "\n",
    "col =  len(small_trajectories)-1\n",
    "\n",
    "for i in range(0,len(small_trajectories[col])):\n",
    "    test_x_axis.append(small_trajectories[col][i][0])\n",
    "    test_y_axis.append(small_trajectories[col][i][1])\n",
    "\n",
    "test_x_axis=np.array(test_x_axis)\n",
    "test_y_axis=np.array(test_y_axis)\n",
    "\n",
    "sns.lineplot(x=test_y_axis, y=test_x_axis)\n",
    "plt.xlim([0,36])\n",
    "plt.ylim([0,35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(x=test_y_axis, y=test_x_axis, color = 'Red', lw =2, estimator=np.max)\n",
    "\n",
    "\n",
    "plt.imshow(small_track)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Create my small track car #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#my_st_car = Car(epsilon=.1, gamma= .5,noise_ratio=.1,allow_noise=True,episode_max = 400000, q_frame =small_Q, avail_actions= actions, vel_max= vel_max, vel_min = vel_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You start at  [31, 8]\n",
      "Velocity is  [0, 0]\n",
      "First digit increments horitzonal movement, second increments vertical\n",
      "Current Episode Count 0\n",
      "Possible Actions:  [[0, 1], [1, 0], [1, 1]]\n",
      "New speed [0, 1]\n",
      "New Position [30, 8]\n",
      "[[1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 9. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]]\n",
      "Current Episode Count 0\n",
      "Possible Actions:  [[0, 0], [0, 1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 2]\n",
      "New Position [28, 8]\n",
      "[[1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 9. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]]\n",
      "Current Episode Count 0\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 3]\n",
      "New Position [25, 8]\n",
      "[[1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 9. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]]\n",
      "Current Episode Count 0\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [21, 8]\n",
      "[[1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 9. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]]\n",
      "Current Episode Count 0\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [17, 8]\n",
      "[[1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 9. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]]\n",
      "Current Episode Count 0\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [13, 8]\n",
      "[[1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 9. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]]\n",
      "Current Episode Count 0\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [9, 8]\n",
      "[[1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 9. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]]\n",
      "Current Episode Count 0\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 3]\n",
      "New Position [6, 8]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]]\n",
      "Current Episode Count 0\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 2]\n",
      "New Position [4, 8]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 0\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [1, 1]\n",
      "New Position [3, 9]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 0\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1]]\n",
      "New speed [2, 0]\n",
      "New Position [3, 11]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 0\n",
      "Possible Actions:  [[0, 0], [0, 1], [1, 0], [1, 1], [-1, 0], [-1, 1]]\n",
      "New speed [3, 0]\n",
      "New Position [3, 14]\n",
      "[[1. 1. 1. 1. 1. 2.]\n",
      " [1. 1. 1. 1. 1. 2.]\n",
      " [1. 1. 1. 1. 1. 2.]\n",
      " [1. 1. 1. 9. 1. 2.]\n",
      " [1. 1. 1. 1. 1. 2.]\n",
      " [1. 1. 1. 1. 1. 2.]]\n",
      "Current Episode Count 0\n",
      "Possible Actions:  [[0, 0], [0, 1], [1, 0], [1, 1], [-1, 0], [-1, 1]]\n",
      "New speed [4, 0]\n",
      "You finished!\n",
      "You start at  [31, 6]\n",
      "Velocity is  [0, 0]\n",
      "First digit increments horitzonal movement, second increments vertical\n",
      "Current Episode Count 1\n",
      "Possible Actions:  [[0, 1], [1, 0], [1, 1]]\n",
      "New speed [0, 1]\n",
      "New Position [30, 6]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 1\n",
      "Possible Actions:  [[0, 0], [0, 1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 2]\n",
      "New Position [28, 6]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 1\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 3]\n",
      "New Position [25, 6]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 1\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [21, 6]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 1\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [17, 6]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 1\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [13, 6]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 1\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 3]\n",
      "New Position [10, 6]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 1\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 2]\n",
      "New Position [8, 6]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 1\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [1, 2]\n",
      "New Position [6, 7]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 1\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [1, 2]\n",
      "New Position [4, 8]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 1\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [2, 1]\n",
      "New Position [3, 10]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 1\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [3, 0]\n",
      "New Position [3, 13]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 1\n",
      "Possible Actions:  [[0, 0], [0, 1], [1, 0], [1, 1], [-1, 0], [-1, 1]]\n",
      "New speed [4, 0]\n",
      "You finished!\n",
      "You start at  [31, 7]\n",
      "Velocity is  [0, 0]\n",
      "First digit increments horitzonal movement, second increments vertical\n",
      "Current Episode Count 2\n",
      "Possible Actions:  [[0, 1], [1, 0], [1, 1]]\n",
      "New speed [0, 1]\n",
      "New Position [30, 7]\n",
      "[[1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 9. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 2\n",
      "Possible Actions:  [[0, 0], [0, 1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 2]\n",
      "New Position [28, 7]\n",
      "[[1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 9. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 2\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 3]\n",
      "New Position [25, 7]\n",
      "[[1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 9. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 2\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [21, 7]\n",
      "[[1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 9. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 2\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [17, 7]\n",
      "[[1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 9. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 2\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [13, 7]\n",
      "[[1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 9. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 2\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [9, 7]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 9. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 2\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [1, 3]\n",
      "New Position [6, 8]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]]\n",
      "Current Episode Count 2\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [1, 2]\n",
      "New Position [4, 9]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 0. 0.]]\n",
      "Current Episode Count 2\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [2, 1]\n",
      "New Position [3, 11]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 2\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [3, 0]\n",
      "New Position [3, 14]\n",
      "[[1. 1. 1. 1. 1. 2.]\n",
      " [1. 1. 1. 1. 1. 2.]\n",
      " [1. 1. 1. 1. 1. 2.]\n",
      " [1. 1. 1. 9. 1. 2.]\n",
      " [1. 1. 1. 1. 1. 2.]\n",
      " [1. 1. 1. 1. 1. 2.]]\n",
      "Current Episode Count 2\n",
      "Possible Actions:  [[0, 0], [0, 1], [1, 0], [1, 1], [-1, 0], [-1, 1]]\n",
      "New speed [4, 0]\n",
      "You finished!\n",
      "You start at  [31, 3]\n",
      "Velocity is  [0, 0]\n",
      "First digit increments horitzonal movement, second increments vertical\n",
      "Current Episode Count 3\n",
      "Possible Actions:  [[0, 1], [1, 0], [1, 1]]\n",
      "New speed [0, 1]\n",
      "New Position [30, 3]\n",
      "[[0. 0. 1. 1. 1. 1.]\n",
      " [0. 0. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 1. 1. 1.]\n",
      " [0. 0. 0. 9. 1. 1.]\n",
      " [0. 0. 0. 1. 1. 1.]]\n",
      "Current Episode Count 3\n",
      "Possible Actions:  [[0, 0], [0, 1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 2]\n",
      "New Position [28, 3]\n",
      "[[0. 0. 1. 1. 1. 1.]\n",
      " [0. 0. 1. 1. 1. 1.]\n",
      " [0. 0. 1. 1. 1. 1.]\n",
      " [0. 0. 1. 9. 1. 1.]\n",
      " [0. 0. 0. 1. 1. 1.]\n",
      " [0. 0. 0. 1. 1. 1.]]\n",
      "Current Episode Count 3\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 3]\n",
      "New Position [25, 3]\n",
      "[[0. 0. 1. 1. 1. 1.]\n",
      " [0. 0. 1. 1. 1. 1.]\n",
      " [0. 0. 1. 1. 1. 1.]\n",
      " [0. 0. 1. 9. 1. 1.]\n",
      " [0. 0. 1. 1. 1. 1.]\n",
      " [0. 0. 1. 1. 1. 1.]]\n",
      "Current Episode Count 3\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [21, 3]\n",
      "[[0. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 9. 1. 1.]\n",
      " [0. 0. 1. 1. 1. 1.]\n",
      " [0. 0. 1. 1. 1. 1.]]\n",
      "Current Episode Count 3\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [17, 3]\n",
      "[[0. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 9. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 3\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [1, 4]\n",
      "New Position [13, 4]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 3\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1], [-1, 0], [-1, -1]]\n",
      "New speed [1, 4]\n",
      "New Position [9, 5]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 3\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1], [-1, 0], [-1, -1]]\n",
      "New speed [2, 3]\n",
      "New Position [6, 7]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 3\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [1, 2]\n",
      "New Position [4, 8]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 3\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [2, 1]\n",
      "New Position [3, 10]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 3\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [3, 0]\n",
      "New Position [3, 13]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 3\n",
      "Possible Actions:  [[0, 0], [0, 1], [1, 0], [1, 1], [-1, 0], [-1, 1]]\n",
      "New speed [4, 0]\n",
      "You finished!\n",
      "You start at  [31, 4]\n",
      "Velocity is  [0, 0]\n",
      "First digit increments horitzonal movement, second increments vertical\n",
      "Current Episode Count 4\n",
      "Possible Actions:  [[0, 1], [1, 0], [1, 1]]\n",
      "New speed [0, 1]\n",
      "New Position [30, 4]\n",
      "[[0. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1.]\n",
      " [0. 0. 1. 1. 1. 1.]\n",
      " [0. 0. 1. 9. 1. 1.]\n",
      " [0. 0. 1. 1. 1. 1.]]\n",
      "Current Episode Count 4\n",
      "Possible Actions:  [[0, 0], [0, 1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 2]\n",
      "New Position [28, 4]\n",
      "[[0. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 9. 1. 1.]\n",
      " [0. 0. 1. 1. 1. 1.]\n",
      " [0. 0. 1. 1. 1. 1.]]\n",
      "Current Episode Count 4\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 3]\n",
      "New Position [25, 4]\n",
      "[[0. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 9. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 4\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [21, 4]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 4\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [17, 4]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 4\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [13, 4]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 4\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [1, 4]\n",
      "New Position [9, 5]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 4\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1], [-1, 0], [-1, -1]]\n",
      "New speed [2, 3]\n",
      "New Position [6, 7]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 4\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [2, 2]\n",
      "New Position [4, 9]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 0. 0.]]\n",
      "Current Episode Count 4\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [3, 1]\n",
      "New Position [3, 12]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 4\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [4, 0]\n",
      "You finished!\n",
      "You start at  [31, 6]\n",
      "Velocity is  [0, 0]\n",
      "First digit increments horitzonal movement, second increments vertical\n",
      "Current Episode Count 5\n",
      "Possible Actions:  [[0, 1], [1, 0], [1, 1]]\n",
      "New speed [0, 1]\n",
      "New Position [30, 6]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 5\n",
      "Possible Actions:  [[0, 0], [0, 1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 2]\n",
      "New Position [28, 6]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 5\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 3]\n",
      "New Position [25, 6]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 5\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [21, 6]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 5\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [17, 6]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 5\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [13, 6]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 5\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [9, 6]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 5\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [1, 3]\n",
      "New Position [6, 7]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 5\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [1, 2]\n",
      "New Position [4, 8]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 5\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [2, 1]\n",
      "New Position [3, 10]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 5\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [3, 0]\n",
      "New Position [3, 13]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 5\n",
      "Possible Actions:  [[0, 0], [0, 1], [1, 0], [1, 1], [-1, 0], [-1, 1]]\n",
      "New speed [4, 0]\n",
      "You finished!\n",
      "You start at  [31, 8]\n",
      "Velocity is  [0, 0]\n",
      "First digit increments horitzonal movement, second increments vertical\n",
      "Current Episode Count 6\n",
      "Possible Actions:  [[0, 1], [1, 0], [1, 1]]\n",
      "New speed [0, 1]\n",
      "New Position [30, 8]\n",
      "[[1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 9. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]]\n",
      "Current Episode Count 6\n",
      "Possible Actions:  [[0, 0], [0, 1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 2]\n",
      "New Position [28, 8]\n",
      "[[1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 9. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]]\n",
      "Current Episode Count 6\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 3]\n",
      "New Position [25, 8]\n",
      "[[1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 9. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]]\n",
      "Current Episode Count 6\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [21, 8]\n",
      "[[1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 9. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]]\n",
      "Current Episode Count 6\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [17, 8]\n",
      "[[1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 9. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]]\n",
      "Current Episode Count 6\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [13, 8]\n",
      "[[1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 9. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]]\n",
      "Current Episode Count 6\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [9, 8]\n",
      "[[1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 9. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]]\n",
      "Current Episode Count 6\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 3]\n",
      "New Position [6, 8]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]]\n",
      "Current Episode Count 6\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 2]\n",
      "New Position [4, 8]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 6\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [1, 1]\n",
      "New Position [3, 9]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 6\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1]]\n",
      "New speed [2, 0]\n",
      "New Position [3, 11]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 6\n",
      "Possible Actions:  [[0, 0], [0, 1], [1, 0], [1, 1], [-1, 0], [-1, 1]]\n",
      "Your entry is invalid, try:\n",
      "[1, 0]\n",
      "New speed [3, 0]\n",
      "New Position [3, 14]\n",
      "[[1. 1. 1. 1. 1. 2.]\n",
      " [1. 1. 1. 1. 1. 2.]\n",
      " [1. 1. 1. 1. 1. 2.]\n",
      " [1. 1. 1. 9. 1. 2.]\n",
      " [1. 1. 1. 1. 1. 2.]\n",
      " [1. 1. 1. 1. 1. 2.]]\n",
      "Current Episode Count 6\n",
      "Possible Actions:  [[0, 0], [0, 1], [1, 0], [1, 1], [-1, 0], [-1, 1]]\n",
      "New speed [3, 0]\n",
      "You finished!\n",
      "You start at  [31, 3]\n",
      "Velocity is  [0, 0]\n",
      "First digit increments horitzonal movement, second increments vertical\n",
      "Current Episode Count 7\n",
      "Possible Actions:  [[0, 1], [1, 0], [1, 1]]\n",
      "New speed [0, 1]\n",
      "New Position [30, 3]\n",
      "[[0. 0. 1. 1. 1. 1.]\n",
      " [0. 0. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 1. 1. 1.]\n",
      " [0. 0. 0. 9. 1. 1.]\n",
      " [0. 0. 0. 1. 1. 1.]]\n",
      "Current Episode Count 7\n",
      "Possible Actions:  [[0, 0], [0, 1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 2]\n",
      "New Position [28, 3]\n",
      "[[0. 0. 1. 1. 1. 1.]\n",
      " [0. 0. 1. 1. 1. 1.]\n",
      " [0. 0. 1. 1. 1. 1.]\n",
      " [0. 0. 1. 9. 1. 1.]\n",
      " [0. 0. 0. 1. 1. 1.]\n",
      " [0. 0. 0. 1. 1. 1.]]\n",
      "Current Episode Count 7\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [1, 3]\n",
      "New Position [25, 4]\n",
      "[[0. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 9. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 7\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [1, 4]\n",
      "New Position [21, 5]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 7\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1], [-1, 0], [-1, -1]]\n",
      "New speed [1, 4]\n",
      "New Position [17, 6]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 7\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1], [-1, 0], [-1, -1]]\n",
      "New speed [1, 4]\n",
      "New Position [13, 7]\n",
      "[[1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 9. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 7\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1], [-1, 0], [-1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [9, 7]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 9. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 7\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 3]\n",
      "New Position [6, 7]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 7\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [1, 2]\n",
      "New Position [4, 8]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 7\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [2, 1]\n",
      "New Position [3, 10]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 7\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [3, 0]\n",
      "New Position [3, 13]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 7\n",
      "Possible Actions:  [[0, 0], [0, 1], [1, 0], [1, 1], [-1, 0], [-1, 1]]\n",
      "New speed [4, 0]\n",
      "You finished!\n",
      "You start at  [31, 4]\n",
      "Velocity is  [0, 0]\n",
      "First digit increments horitzonal movement, second increments vertical\n",
      "Current Episode Count 8\n",
      "Possible Actions:  [[0, 1], [1, 0], [1, 1]]\n",
      "New speed [0, 1]\n",
      "New Position [30, 4]\n",
      "[[0. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1.]\n",
      " [0. 0. 1. 1. 1. 1.]\n",
      " [0. 0. 1. 9. 1. 1.]\n",
      " [0. 0. 1. 1. 1. 1.]]\n",
      "Current Episode Count 8\n",
      "Possible Actions:  [[0, 0], [0, 1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 2]\n",
      "New Position [28, 4]\n",
      "[[0. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 9. 1. 1.]\n",
      " [0. 0. 1. 1. 1. 1.]\n",
      " [0. 0. 1. 1. 1. 1.]]\n",
      "Current Episode Count 8\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 3]\n",
      "New Position [25, 4]\n",
      "[[0. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 9. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 8\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [21, 4]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 8\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [17, 4]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 8\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [13, 4]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 8\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [1, 4]\n",
      "New Position [9, 5]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 8\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1], [-1, 0], [-1, -1]]\n",
      "New speed [1, 3]\n",
      "New Position [6, 6]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 8\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [2, 2]\n",
      "New Position [4, 8]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 8\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [3, 1]\n",
      "New Position [3, 11]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 8\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [4, 0]\n",
      "New Position [3, 15]\n",
      "[[1. 1. 1. 1. 2. 2.]\n",
      " [1. 1. 1. 1. 2. 2.]\n",
      " [1. 1. 1. 1. 2. 2.]\n",
      " [1. 1. 1. 9. 2. 2.]\n",
      " [1. 1. 1. 1. 2. 2.]\n",
      " [1. 1. 1. 1. 2. 2.]]\n",
      "Current Episode Count 8\n",
      "Possible Actions:  [[0, 0], [0, 1], [-1, 0], [-1, 1]]\n",
      "New speed [4, 0]\n",
      "You finished!\n",
      "You start at  [31, 7]\n",
      "Velocity is  [0, 0]\n",
      "First digit increments horitzonal movement, second increments vertical\n",
      "Current Episode Count 9\n",
      "Possible Actions:  [[0, 1], [1, 0], [1, 1]]\n",
      "New speed [0, 1]\n",
      "New Position [30, 7]\n",
      "[[1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 9. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 9\n",
      "Possible Actions:  [[0, 0], [0, 1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 2]\n",
      "New Position [28, 7]\n",
      "[[1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 9. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 9\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 3]\n",
      "New Position [25, 7]\n",
      "[[1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 9. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 9\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [21, 7]\n",
      "[[1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 9. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 9\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [17, 7]\n",
      "[[1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 9. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 9\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [13, 7]\n",
      "[[1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 9. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 9\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [9, 7]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 9. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 9\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 3]\n",
      "New Position [6, 7]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 9\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 2]\n",
      "New Position [4, 7]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 9\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [1, 1]\n",
      "New Position [3, 8]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 9\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1]]\n",
      "New speed [2, 0]\n",
      "New Position [3, 10]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 9\n",
      "Possible Actions:  [[0, 0], [0, 1], [1, 0], [1, 1], [-1, 0], [-1, 1]]\n",
      "New speed [3, 0]\n",
      "New Position [3, 13]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 9\n",
      "Possible Actions:  [[0, 0], [0, 1], [1, 0], [1, 1], [-1, 0], [-1, 1]]\n",
      "New speed [4, 0]\n",
      "You finished!\n",
      "You start at  [31, 8]\n",
      "Velocity is  [0, 0]\n",
      "First digit increments horitzonal movement, second increments vertical\n",
      "Current Episode Count 10\n",
      "Possible Actions:  [[0, 1], [1, 0], [1, 1]]\n",
      "New speed [0, 1]\n",
      "New Position [30, 8]\n",
      "[[1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 9. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]]\n",
      "Current Episode Count 10\n",
      "Possible Actions:  [[0, 0], [0, 1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 2]\n",
      "New Position [28, 8]\n",
      "[[1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 9. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]]\n",
      "Current Episode Count 10\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 3]\n",
      "New Position [25, 8]\n",
      "[[1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 9. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]]\n",
      "Current Episode Count 10\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [21, 8]\n",
      "[[1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 9. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]]\n",
      "Current Episode Count 10\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [17, 8]\n",
      "[[1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 9. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]]\n",
      "Current Episode Count 10\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [13, 8]\n",
      "[[1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 9. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]]\n",
      "Current Episode Count 10\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [9, 8]\n",
      "[[1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 9. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]]\n",
      "Current Episode Count 10\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 3]\n",
      "New Position [6, 8]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]]\n",
      "Current Episode Count 10\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 2]\n",
      "New Position [4, 8]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 10\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [1, 1]\n",
      "New Position [3, 9]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 10\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1]]\n",
      "New speed [2, 0]\n",
      "New Position [3, 11]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 10\n",
      "Possible Actions:  [[0, 0], [0, 1], [1, 0], [1, 1], [-1, 0], [-1, 1]]\n",
      "New speed [3, 0]\n",
      "New Position [3, 14]\n",
      "[[1. 1. 1. 1. 1. 2.]\n",
      " [1. 1. 1. 1. 1. 2.]\n",
      " [1. 1. 1. 1. 1. 2.]\n",
      " [1. 1. 1. 9. 1. 2.]\n",
      " [1. 1. 1. 1. 1. 2.]\n",
      " [1. 1. 1. 1. 1. 2.]]\n",
      "Current Episode Count 10\n",
      "Possible Actions:  [[0, 0], [0, 1], [1, 0], [1, 1], [-1, 0], [-1, 1]]\n",
      "New speed [4, 0]\n",
      "You finished!\n",
      "You start at  [31, 7]\n",
      "Velocity is  [0, 0]\n",
      "First digit increments horitzonal movement, second increments vertical\n",
      "Current Episode Count 11\n",
      "Possible Actions:  [[0, 1], [1, 0], [1, 1]]\n",
      "New speed [0, 1]\n",
      "New Position [30, 7]\n",
      "[[1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 9. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 11\n",
      "Possible Actions:  [[0, 0], [0, 1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 2]\n",
      "New Position [28, 7]\n",
      "[[1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 9. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 11\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 3]\n",
      "New Position [25, 7]\n",
      "[[1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 9. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 11\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [21, 7]\n",
      "[[1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 9. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 11\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [17, 7]\n",
      "[[1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 9. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 11\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [13, 7]\n",
      "[[1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 9. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 11\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [9, 7]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 9. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 11\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 3]\n",
      "New Position [6, 7]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 11\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [1, 2]\n",
      "New Position [4, 8]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 11\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [2, 1]\n",
      "New Position [3, 10]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 11\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [3, 0]\n",
      "New Position [3, 13]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 11\n",
      "Possible Actions:  [[0, 0], [0, 1], [1, 0], [1, 1], [-1, 0], [-1, 1]]\n",
      "New speed [4, 0]\n",
      "You finished!\n",
      "You start at  [31, 4]\n",
      "Velocity is  [0, 0]\n",
      "First digit increments horitzonal movement, second increments vertical\n",
      "Current Episode Count 12\n",
      "Possible Actions:  [[0, 1], [1, 0], [1, 1]]\n",
      "New speed [0, 1]\n",
      "New Position [30, 4]\n",
      "[[0. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1.]\n",
      " [0. 0. 1. 1. 1. 1.]\n",
      " [0. 0. 1. 9. 1. 1.]\n",
      " [0. 0. 1. 1. 1. 1.]]\n",
      "Current Episode Count 12\n",
      "Possible Actions:  [[0, 0], [0, 1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 2]\n",
      "New Position [28, 4]\n",
      "[[0. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 9. 1. 1.]\n",
      " [0. 0. 1. 1. 1. 1.]\n",
      " [0. 0. 1. 1. 1. 1.]]\n",
      "Current Episode Count 12\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 3]\n",
      "New Position [25, 4]\n",
      "[[0. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 9. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 12\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [21, 4]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 12\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [17, 4]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 12\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [13, 4]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 12\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [9, 4]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 12\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [1, 3]\n",
      "New Position [6, 5]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 12\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [2, 2]\n",
      "New Position [4, 7]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 12\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [3, 1]\n",
      "New Position [3, 10]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 12\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [4, 0]\n",
      "New Position [3, 14]\n",
      "[[1. 1. 1. 1. 1. 2.]\n",
      " [1. 1. 1. 1. 1. 2.]\n",
      " [1. 1. 1. 1. 1. 2.]\n",
      " [1. 1. 1. 9. 1. 2.]\n",
      " [1. 1. 1. 1. 1. 2.]\n",
      " [1. 1. 1. 1. 1. 2.]]\n",
      "Current Episode Count 12\n",
      "Possible Actions:  [[0, 0], [0, 1], [-1, 0], [-1, 1]]\n",
      "New speed [4, 0]\n",
      "You finished!\n",
      "You start at  [31, 5]\n",
      "Velocity is  [0, 0]\n",
      "First digit increments horitzonal movement, second increments vertical\n",
      "Current Episode Count 13\n",
      "Possible Actions:  [[0, 1], [1, 0], [1, 1]]\n",
      "New speed [0, 1]\n",
      "New Position [30, 5]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 9. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 13\n",
      "Possible Actions:  [[0, 0], [0, 1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 2]\n",
      "New Position [28, 5]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 13\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 3]\n",
      "New Position [25, 5]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 13\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [21, 5]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 13\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [17, 5]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 13\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [13, 5]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 13\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [9, 5]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 13\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [1, 3]\n",
      "New Position [6, 6]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 13\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [2, 2]\n",
      "New Position [4, 8]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 13\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [3, 1]\n",
      "New Position [3, 11]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 13\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [4, 0]\n",
      "New Position [3, 15]\n",
      "[[1. 1. 1. 1. 2. 2.]\n",
      " [1. 1. 1. 1. 2. 2.]\n",
      " [1. 1. 1. 1. 2. 2.]\n",
      " [1. 1. 1. 9. 2. 2.]\n",
      " [1. 1. 1. 1. 2. 2.]\n",
      " [1. 1. 1. 1. 2. 2.]]\n",
      "Current Episode Count 13\n",
      "Possible Actions:  [[0, 0], [0, 1], [-1, 0], [-1, 1]]\n",
      "New speed [4, 0]\n",
      "You finished!\n",
      "You start at  [31, 7]\n",
      "Velocity is  [0, 0]\n",
      "First digit increments horitzonal movement, second increments vertical\n",
      "Current Episode Count 14\n",
      "Possible Actions:  [[0, 1], [1, 0], [1, 1]]\n",
      "New speed [0, 1]\n",
      "New Position [30, 7]\n",
      "[[1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 9. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 14\n",
      "Possible Actions:  [[0, 0], [0, 1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 2]\n",
      "New Position [28, 7]\n",
      "[[1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 9. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 14\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 3]\n",
      "New Position [25, 7]\n",
      "[[1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 9. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 14\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [21, 7]\n",
      "[[1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 9. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 14\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [17, 7]\n",
      "[[1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 9. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 14\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [13, 7]\n",
      "[[1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 9. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 14\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [9, 7]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 9. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 14\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 3]\n",
      "New Position [6, 7]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 14\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [1, 2]\n",
      "New Position [4, 8]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 14\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [2, 1]\n",
      "New Position [3, 10]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 14\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [3, 0]\n",
      "New Position [3, 13]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 14\n",
      "Possible Actions:  [[0, 0], [0, 1], [1, 0], [1, 1], [-1, 0], [-1, 1]]\n",
      "New speed [4, 0]\n",
      "You finished!\n",
      "You start at  [31, 8]\n",
      "Velocity is  [0, 0]\n",
      "First digit increments horitzonal movement, second increments vertical\n",
      "Current Episode Count 15\n",
      "Possible Actions:  [[0, 1], [1, 0], [1, 1]]\n",
      "New speed [0, 1]\n",
      "New Position [30, 8]\n",
      "[[1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 9. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]]\n",
      "Current Episode Count 15\n",
      "Possible Actions:  [[0, 0], [0, 1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 2]\n",
      "New Position [28, 8]\n",
      "[[1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 9. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]]\n",
      "Current Episode Count 15\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 3]\n",
      "New Position [25, 8]\n",
      "[[1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 9. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]]\n",
      "Current Episode Count 15\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [21, 8]\n",
      "[[1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 9. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]]\n",
      "Current Episode Count 15\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [17, 8]\n",
      "[[1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 9. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]]\n",
      "Current Episode Count 15\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [13, 8]\n",
      "[[1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 9. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]]\n",
      "Current Episode Count 15\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [9, 8]\n",
      "[[1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 9. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]]\n",
      "Current Episode Count 15\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [1, 3]\n",
      "You went out of bounds\n",
      "You start at  [31, 5]\n",
      "Velocity is  [0, 0]\n",
      "First digit increments horitzonal movement, second increments vertical\n",
      "Current Episode Count 16\n",
      "Possible Actions:  [[0, 1], [1, 0], [1, 1]]\n",
      "New speed [0, 1]\n",
      "New Position [30, 5]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 9. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 16\n",
      "Possible Actions:  [[0, 0], [0, 1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 2]\n",
      "New Position [28, 5]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 16\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 3]\n",
      "New Position [25, 5]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 16\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [21, 5]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 16\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [17, 5]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 16\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [13, 5]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 16\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [1, 3]\n",
      "New Position [10, 6]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 16\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [1, 2]\n",
      "New Position [8, 7]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 9. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 16\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [1, 2]\n",
      "New Position [6, 8]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]]\n",
      "Current Episode Count 16\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [1, 2]\n",
      "New Position [4, 9]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 0. 0.]]\n",
      "Current Episode Count 16\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [2, 1]\n",
      "New Position [3, 11]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 16\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [3, 0]\n",
      "New Position [3, 14]\n",
      "[[1. 1. 1. 1. 1. 2.]\n",
      " [1. 1. 1. 1. 1. 2.]\n",
      " [1. 1. 1. 1. 1. 2.]\n",
      " [1. 1. 1. 9. 1. 2.]\n",
      " [1. 1. 1. 1. 1. 2.]\n",
      " [1. 1. 1. 1. 1. 2.]]\n",
      "Current Episode Count 16\n",
      "Possible Actions:  [[0, 0], [0, 1], [1, 0], [1, 1], [-1, 0], [-1, 1]]\n",
      "New speed [4, 0]\n",
      "You finished!\n",
      "You start at  [31, 7]\n",
      "Velocity is  [0, 0]\n",
      "First digit increments horitzonal movement, second increments vertical\n",
      "Current Episode Count 17\n",
      "Possible Actions:  [[0, 1], [1, 0], [1, 1]]\n",
      "New speed [0, 1]\n",
      "New Position [30, 7]\n",
      "[[1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 9. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 17\n",
      "Possible Actions:  [[0, 0], [0, 1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 2]\n",
      "New Position [28, 7]\n",
      "[[1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 9. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 17\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 3]\n",
      "New Position [25, 7]\n",
      "[[1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 9. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 17\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [21, 7]\n",
      "[[1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 9. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 17\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [17, 7]\n",
      "[[1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 9. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 17\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [13, 7]\n",
      "[[1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 9. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 17\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [9, 7]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 9. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 17\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 3]\n",
      "New Position [6, 7]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 17\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 2]\n",
      "New Position [4, 7]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 17\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [1, 1]\n",
      "New Position [3, 8]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 17\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1]]\n",
      "New speed [2, 0]\n",
      "New Position [3, 10]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 17\n",
      "Possible Actions:  [[0, 0], [0, 1], [1, 0], [1, 1], [-1, 0], [-1, 1]]\n",
      "New speed [3, 0]\n",
      "New Position [3, 13]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 17\n",
      "Possible Actions:  [[0, 0], [0, 1], [1, 0], [1, 1], [-1, 0], [-1, 1]]\n",
      "New speed [4, 0]\n",
      "You finished!\n",
      "You start at  [31, 6]\n",
      "Velocity is  [0, 0]\n",
      "First digit increments horitzonal movement, second increments vertical\n",
      "Current Episode Count 18\n",
      "Possible Actions:  [[0, 1], [1, 0], [1, 1]]\n",
      "New speed [0, 1]\n",
      "New Position [30, 6]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 18\n",
      "Possible Actions:  [[0, 0], [0, 1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 2]\n",
      "New Position [28, 6]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 18\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 3]\n",
      "New Position [25, 6]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 18\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [21, 6]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 18\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [17, 6]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 18\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [13, 6]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 18\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [9, 6]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 18\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [1, 3]\n",
      "New Position [6, 7]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 18\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [1, 2]\n",
      "New Position [4, 8]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 18\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [2, 1]\n",
      "New Position [3, 10]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 18\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [3, 0]\n",
      "New Position [3, 13]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 18\n",
      "Possible Actions:  [[0, 0], [0, 1], [1, 0], [1, 1], [-1, 0], [-1, 1]]\n",
      "New speed [4, 0]\n",
      "You finished!\n",
      "You start at  [31, 7]\n",
      "Velocity is  [0, 0]\n",
      "First digit increments horitzonal movement, second increments vertical\n",
      "Current Episode Count 19\n",
      "Possible Actions:  [[0, 1], [1, 0], [1, 1]]\n",
      "New speed [0, 1]\n",
      "New Position [30, 7]\n",
      "[[1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 9. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 19\n",
      "Possible Actions:  [[0, 0], [0, 1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 2]\n",
      "New Position [28, 7]\n",
      "[[1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 9. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 19\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 3]\n",
      "New Position [25, 7]\n",
      "[[1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 9. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 19\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [21, 7]\n",
      "[[1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 9. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 19\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [17, 7]\n",
      "[[1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 9. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 19\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [13, 7]\n",
      "[[1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 9. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 19\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 4]\n",
      "New Position [9, 7]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 9. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 19\n",
      "Possible Actions:  [[0, 0], [0, -1], [1, 0], [1, -1]]\n",
      "New speed [0, 3]\n",
      "New Position [6, 7]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 19\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1]]\n",
      "New speed [1, 2]\n",
      "New Position [4, 8]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "Current Episode Count 19\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [2, 1]\n",
      "New Position [3, 10]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 19\n",
      "Possible Actions:  [[0, 0], [0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n",
      "New speed [3, 0]\n",
      "New Position [3, 13]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 9. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Current Episode Count 19\n",
      "Possible Actions:  [[0, 0], [0, 1], [1, 0], [1, 1], [-1, 0], [-1, 1]]\n",
      "New speed [4, 0]\n",
      "You finished!\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "while my_st_car.episode_count < 10:\n",
    "     my_st_car.let_me_take_the_wheel(s_track.assign_starting_point(), s_track)\n",
    "human_st_10_eps_frame = np.copy(my_st_car.q)\n",
    "\n",
    "while my_st_car.episode_count < 20:\n",
    "    my_st_car.let_me_take_the_wheel(s_track.assign_starting_point(), s_track)\n",
    "\n",
    "human_st_20_eps_frame = np.copy(my_st_car.q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Create small track hybrid car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_hybrid_car = Car(epsilon = .1, gamma = .5, noise_ratio=.1, allow_noise=True, episode_max= 400000, q_frame= human_st_20_eps_frame, avail_actions= actions, vel_max= vel_max, vel_min = vel_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_hybrid_car.state_action_counts = my_st_car.state_action_counts * 10   # i want to give more weight to the human moves\n",
    "st_hybrid_car.episode_count = my_st_car.episode_count * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode count 400000\n",
      "highest reward 10\n",
      "last short average 0.9033333333333333\n",
      "last long avg rew 1.032\n",
      "last 50 quantile 8.0\n",
      "total quantile 9.0\n",
      "Victory Count 267393\n",
      "% Vicotry 0.6684825\n",
      "Diff from Epsilon -0.2572416666666667\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "\n",
    "while st_hybrid_car.can_end == False:\n",
    "    st_hybrid_car.run_episode(s_track.assign_starting_point(), s_track)\n",
    "   \n",
    "st_hybrid_car.print_stats()    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Create small track no noise car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_nn_racecar = Car(epsilon = .1, gamma = .5, noise_ratio=.1, allow_noise=False, episode_max= 400000, q_frame= small_Q, avail_actions= actions, vel_max= vel_max, vel_min = vel_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode count 400000\n",
      "highest reward 10\n",
      "last short average 3.203333333333333\n",
      "last long avg rew 3.8415\n",
      "last 50 quantile 8.5\n",
      "total quantile 10.0\n",
      "Victory Count 302484\n",
      "% Vicotry 0.75621\n",
      "Diff from Epsilon -0.1597666666666666\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "\n",
    "while small_nn_racecar.can_end == False:\n",
    "    small_nn_racecar.run_episode(s_track.assign_starting_point(), s_track)\n",
    "   \n",
    "small_nn_racecar.print_stats()    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Create small track no noise hybrid car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_nn_hybrid_car = Car(epsilon = .1, gamma = .5, noise_ratio=.1, allow_noise=False, episode_max= 400000, q_frame= small_Q, avail_actions= actions, vel_max= vel_max, vel_min = vel_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_nn_hybrid_car.state_action_counts = my_st_car.state_action_counts * 10   # i want to give more weight to the human moves\n",
    "small_nn_hybrid_car.episode_count = my_st_car.episode_count * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode count 400000\n",
      "highest reward 10\n",
      "last short average 5.083333333333333\n",
      "last long avg rew 4.755\n",
      "last 50 quantile 9.0\n",
      "total quantile 10.0\n",
      "Victory Count 313303\n",
      "% Vicotry 0.7832575\n",
      "Diff from Epsilon -0.1297138888888889\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "\n",
    "\n",
    "while small_nn_hybrid_car.can_end == False:\n",
    "    small_nn_hybrid_car.run_episode(s_track.assign_starting_point(), s_track)\n",
    "   \n",
    "small_nn_hybrid_car.print_stats()    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Car_Type</th>\n",
       "      <th>Total_Episodes</th>\n",
       "      <th>Total_Finishes</th>\n",
       "      <th>Final_Victory_Pct</th>\n",
       "      <th>Last_50_Avg_Reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ST Racecar with Noise</td>\n",
       "      <td>400000</td>\n",
       "      <td>280344</td>\n",
       "      <td>0.700860</td>\n",
       "      <td>0.136667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ST Racecar with Noise and Human Boost</td>\n",
       "      <td>400000</td>\n",
       "      <td>267393</td>\n",
       "      <td>0.668482</td>\n",
       "      <td>0.903333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ST Racecar with No Noise</td>\n",
       "      <td>400000</td>\n",
       "      <td>302484</td>\n",
       "      <td>0.756210</td>\n",
       "      <td>3.203333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ST Racecar with No Noise and Human Boost</td>\n",
       "      <td>400000</td>\n",
       "      <td>313303</td>\n",
       "      <td>0.783258</td>\n",
       "      <td>5.083333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Car_Type  Total_Episodes  Total_Finishes  \\\n",
       "0                     ST Racecar with Noise          400000          280344   \n",
       "1     ST Racecar with Noise and Human Boost          400000          267393   \n",
       "2                  ST Racecar with No Noise          400000          302484   \n",
       "3  ST Racecar with No Noise and Human Boost          400000          313303   \n",
       "\n",
       "   Final_Victory_Pct  Last_50_Avg_Reward  \n",
       "0           0.700860            0.136667  \n",
       "1           0.668482            0.903333  \n",
       "2           0.756210            3.203333  \n",
       "3           0.783258            5.083333  "
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st_car_meta_data = pd.DataFrame({\n",
    "    'Car_Type' : ['ST Racecar with Noise', 'ST Racecar with Noise and Human Boost', 'ST Racecar with No Noise','ST Racecar with No Noise and Human Boost'],\n",
    "    'Total_Episodes' : [small_racecar.episode_count, st_hybrid_car.episode_count, small_nn_racecar.episode_count, small_nn_hybrid_car.episode_count],\n",
    "    'Total_Finishes' : [small_racecar.victory_count, st_hybrid_car.victory_count, small_nn_racecar.victory_count, small_nn_hybrid_car.victory_count],\n",
    "    'Final_Victory_Pct' : [small_racecar.victory_count/small_racecar.episode_count, st_hybrid_car.victory_count/st_hybrid_car.episode_count, small_nn_racecar.victory_count/small_nn_racecar.episode_count, small_nn_hybrid_car.victory_count/small_nn_hybrid_car.episode_count],\n",
    "    'Last_50_Avg_Reward' : [small_racecar.last_short_rew, st_hybrid_car.last_short_rew, small_nn_racecar.last_short_rew, small_nn_hybrid_car.last_short_rew]\n",
    "})\n",
    "\n",
    "st_car_meta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Car_Type</th>\n",
       "      <th>Total_Episodes</th>\n",
       "      <th>Total_Finishes</th>\n",
       "      <th>Final_Victory_Pct</th>\n",
       "      <th>Last_50_Avg_Reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LT Racecar with Noise</td>\n",
       "      <td>140734</td>\n",
       "      <td>125394</td>\n",
       "      <td>0.891000</td>\n",
       "      <td>8.113333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LT Racecar with No Noise</td>\n",
       "      <td>68643</td>\n",
       "      <td>61161</td>\n",
       "      <td>0.891001</td>\n",
       "      <td>9.080000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Car_Type  Total_Episodes  Total_Finishes  \\\n",
       "0     LT Racecar with Noise          140734          125394   \n",
       "2  LT Racecar with No Noise           68643           61161   \n",
       "\n",
       "   Final_Victory_Pct  Last_50_Avg_Reward  \n",
       "0           0.891000            8.113333  \n",
       "2           0.891001            9.080000  "
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lt_car_meta_data.filter(items = [0,2],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Car_Type</th>\n",
       "      <th>Total_Episodes</th>\n",
       "      <th>Total_Finishes</th>\n",
       "      <th>Final_Victory_Pct</th>\n",
       "      <th>Last_50_Avg_Reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ST Racecar with Noise</td>\n",
       "      <td>400000</td>\n",
       "      <td>280344</td>\n",
       "      <td>0.70086</td>\n",
       "      <td>0.136667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ST Racecar with No Noise</td>\n",
       "      <td>400000</td>\n",
       "      <td>302484</td>\n",
       "      <td>0.75621</td>\n",
       "      <td>3.203333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Car_Type  Total_Episodes  Total_Finishes  \\\n",
       "0     ST Racecar with Noise          400000          280344   \n",
       "2  ST Racecar with No Noise          400000          302484   \n",
       "\n",
       "   Final_Victory_Pct  Last_50_Avg_Reward  \n",
       "0            0.70086            0.136667  \n",
       "2            0.75621            3.203333  "
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st_car_meta_data.filter(items = [0,2], axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(small_track)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASkAAAD5CAYAAAB70MMZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAM80lEQVR4nO3dX4xc9XnG8e9bZ20XQxVcqLUyVh0oUoVoY9DWcRUU0aJELopkkCIKF5EvUDeqghQqKtWlUkMvKtGqYOWiIjLFxW0pgQYQvkBpiIuEclHApsYYnD8bYhRbiw0iEfTGwfD2Yo7VYb07u96ZnfN65/uRRnvmN2fmPDrrfXzOmd/ORmYiSVX9StsBJKkXS0pSaZaUpNIsKUmlWVKSSrOkJJX2iX6eHBFbgW8AK4B/ysx7e62/Mlblatb0s0kN2akNfr/OJ79z8dttRzgnBw6deiczL+21zqJLKiJWAP8IfB44BrwUEXsz8/W5nrOaNXwmbljsJtWCqbu2tB1B5+DFP/5m2xHOyYrxqTfnW6ef073NwFRmvpGZvwS+BWzr4/Uk6Sz9lNR64Gdd9481Y5I0MH1dk1qIiJgEJgFWc8FSb07SMtPPkdRxYEPX/cuasY/JzF2ZOZGZE2Os6mNzkkZRPyX1EnBlRHwqIlYCtwJ7BxNLkjoWfbqXmacj4g7gP+lMQdidma8NLJnOydRO34XT8tTXNanMfAZ4ZkBZJOkszjiXVJolJak0S0pSaZaUpNIsKUmlWVKSSlvyX4vR4DgXSqPIIylJpVlSkkqzpCSVZklJKs2SklSaJSWpNKcgFOIUA+lsHklJKs2SklSaJSWpNEtKUmmWlKTSLClJpVlSkkqzpCSVZklJKs2SklSaJSWpNEtKUmmWlKTS+voUhIg4CrwPfAiczsyJQYSSpDMG8VEtf5CZ7wzgdSTpLJ7uSSqt35JK4LsRcSAiJgcRSJK69Xu6d11mHo+I3wCejYgfZObz3Ss05TUJsJoL+tycpFHT15FUZh5vvp4EngI2z7LOrsycyMyJMVb1szlJI2jRJRURayLiojPLwBeAw4MKJknQ3+neOuCpiDjzOv+emd8ZSCpJaiy6pDLzDeDTA8wiSWdxCoKk0iwpSaVZUpJKs6QklWZJSSrNkpJU2iA+BUED8lt/9t89H5/auWVISaQ6PJKSVJolJak0S0pSaZaUpNIsKUmlWVKSSnMKwnmk1xQFpydoufJISlJplpSk0iwpSaVZUpJKs6QklWZJSSotMnNoG/u1WJufiRuGtj11OD1heZnv0zLOJ9/Lbx/IzIle63gkJak0S0pSaZaUpNIsKUmlWVKSSrOkJJVmSUkqbd6PaomI3cAXgZOZeXUzthZ4DNgIHAVuycyfL11M6fyznOYztWkhR1IPA1tnjO0A9mXmlcC+5r4kDdy8JZWZzwPvzhjeBuxplvcANw02liR1LPaTOddl5nSz/Bawbq4VI2ISmARYzQWL3JykUdX3hfPs/PLfnL8AmJm7MnMiMyfGWNXv5iSNmMWW1ImIGAdovp4cXCRJ+n+LLam9wPZmeTvw9GDiSNLHLWQKwqPA9cAlEXEM+DpwL/B4RNwOvAncspQhpaqcZrD05i2pzLxtjof8YChJS84Z55JKs6QklWZJSSrNkpJUmiUlqbTF/lqMtKw4laAuj6QklWZJSSrNkpJUmiUlqTRLSlJplpSk0pyCoJHgFIPzl0dSkkqzpCSVZklJKs2SklSaJSWpNEtKUmmWlKTSnCe1TEzt3NJ2BGlJeCQlqTRLSlJplpSk0iwpSaVZUpJKs6QklTbvFISI2A18ETiZmVc3Y/cAfwK83ax2d2Y+s1Qh1eE0A42ihRxJPQxsnWV8Z2Zuam4WlKQlMW9JZebzwLtDyCJJZ+nnmtQdEXEoInZHxMUDSyRJXRZbUg8AVwCbgGngvrlWjIjJiNgfEfs/4NQiNydpVC2qpDLzRGZ+mJkfAQ8Cm3usuyszJzJzYoxVi80paUQtqqQiYrzr7s3A4cHEkaSPW8gUhEeB64FLIuIY8HXg+ojYBCRwFPjK0kUcHU4xkM42b0ll5m2zDD+0BFkk6SzOOJdUmiUlqTRLSlJplpSk0iwpSaVZUpJK86/FDJlzoaRz45GUpNIsKUmlWVKSSrOkJJVmSUkqzZKSVJpTEJaA0wykwfFISlJplpSk0iwpSaVZUpJKs6QklWZJSSrNKQiL5DQDaTg8kpJUmiUlqTRLSlJplpSk0iwpSaVZUpJKm3cKQkRsAP4FWAcksCszvxERa4HHgI3AUeCWzPz50kUdLqcYSDUs5EjqNHBXZl4FbAG+GhFXATuAfZl5JbCvuS9JAzVvSWXmdGa+3Cy/DxwB1gPbgD3NanuAm5Yoo6QRdk7XpCJiI3AN8AKwLjOnm4feonM6KEkDteCSiogLgSeAOzPzve7HMjPpXK+a7XmTEbE/IvZ/wKm+wkoaPQsqqYgYo1NQj2Tmk83wiYgYbx4fB07O9tzM3JWZE5k5McaqQWSWNELmLamICOAh4Ehm3t/10F5ge7O8HXh68PEkjbqFfArCZ4EvA69GxMFm7G7gXuDxiLgdeBO4ZUkSShpp85ZUZn4fiDkevmGwcYbLuVBSfc44l1SaJSWpNEtKUmmWlKTSLClJpVlSkkpb9n8txmkG0vnNIylJpVlSkkqzpCSVZklJKs2SklSaJSWptGUxBcFpBtLy5ZGUpNIsKUmlWVKSSrOkJJVmSUkqzZKSVNp5MQXBKQbS6PJISlJplpSk0iwpSaVZUpJKs6QklWZJSSpt3pKKiA0R8VxEvB4Rr0XE15rxeyLieEQcbG43Ln1cSaNmIfOkTgN3ZebLEXERcCAinm0e25mZ/zCIIM6FkjSbeUsqM6eB6Wb5/Yg4Aqxf6mCSBOd4TSoiNgLXAC80Q3dExKGI2B0RFw86nCQtuKQi4kLgCeDOzHwPeAC4AthE50jrvjmeNxkR+yNi/wec6j+xpJGyoJKKiDE6BfVIZj4JkJknMvPDzPwIeBDYPNtzM3NXZk5k5sQYqwaVW9KIWMi7ewE8BBzJzPu7xse7VrsZODz4eJJG3ULe3fss8GXg1Yg42IzdDdwWEZuABI4CX1mCfJJG3ELe3fs+ELM89Mzg40jSxznjXFJplpSk0iwpSaVZUpJKs6QklWZJSSptqH8t5tSGNUzd5acdSFo4j6QklWZJSSrNkpJUmiUlqTRLSlJplpSk0iwpSaVZUpJKs6QklWZJSSrNkpJUmiUlqTRLSlJplpSk0iwpSaVZUpJKs6QklWZJSSrNkpJUmiUlqTRLSlJpkZnD21jE28CbXUOXAO8MLcD8zNNbtTxQL5N5epuZ5zcz89JeTxhqSZ218Yj9mTnRWoAZzNNbtTxQL5N5eltMHk/3JJVmSUkqre2S2tXy9mcyT2/V8kC9TObp7ZzztHpNSpLm0/aRlCT11EpJRcTWiPhhRExFxI42MszIczQiXo2IgxGxv6UMuyPiZEQc7hpbGxHPRsSPm68Xt5znnog43uyngxFx4xDzbIiI5yLi9Yh4LSK+1oy3so965GllH0XE6oh4MSJeafL8TTP+qYh4oflZeywiVg4jzzyZHo6In3bto009Xygzh3oDVgA/AS4HVgKvAFcNO8eMTEeBS1rO8DngWuBw19jfAzua5R3A37Wc5x7gz1vaP+PAtc3yRcCPgKva2kc98rSyj4AALmyWx4AXgC3A48Ctzfg3gT8tkOlh4EsLfZ02jqQ2A1OZ+UZm/hL4FrCthRylZObzwLszhrcBe5rlPcBNLedpTWZOZ+bLzfL7wBFgPS3tox55WpEd/9vcHWtuCfwh8O1mfNj/hubKdE7aKKn1wM+67h+jxW9uI4HvRsSBiJhsOUu3dZk53Sy/BaxrM0zjjog41JwODu30s1tEbASuofM/c+v7aEYeaGkfRcSKiDgInASepXPG8ovMPN2sMvSftZmZMvPMPvrbZh/tjIhVvV7DC+cd12XmtcAfAV+NiM+1HWim7Bwzt/1W7APAFcAmYBq4b9gBIuJC4Angzsx8r/uxNvbRLHla20eZ+WFmbgIuo3PG8tvD2vZcZmaKiKuBv6ST7feAtcBf9HqNNkrqOLCh6/5lzVhrMvN48/Uk8BSdb3AFJyJiHKD5erLNMJl5ovlH9xHwIEPeTxExRqcQHsnMJ5vh1vbRbHna3kdNhl8AzwG/D3wyIj7RPNTaz1pXpq3NqXJm5ingn5lnH7VRUi8BVzbvOqwEbgX2tpADgIhYExEXnVkGvgAc7v2sodkLbG+WtwNPt5jlTAmccTND3E8REcBDwJHMvL/roVb20Vx52tpHEXFpRHyyWf5V4PN0rpM9B3ypWW2o/4bmyPSDrv9Ugs41st77aNjvQjRX+m+k827IT4C/aiNDV5bL6bzD+ArwWlt5gEfpnB58QOfawe3ArwP7gB8D3wPWtpznX4FXgUN0ymF8iHmuo3Mqdwg42NxubGsf9cjTyj4Cfhf4n2a7h4G/bsYvB14EpoD/AFYN8Xs2V6b/avbRYeDfaN4BnOvmjHNJpXnhXFJplpSk0iwpSaVZUpJKs6QklWZJSSrNkpJUmiUlqbT/AydNBTEhz2sSAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(large_track)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Car_Type</th>\n",
       "      <th>Total_Episodes</th>\n",
       "      <th>Total_Finishes</th>\n",
       "      <th>Final_Victory_Pct</th>\n",
       "      <th>Last_50_Avg_Reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LT Racecar with Noise</td>\n",
       "      <td>140734</td>\n",
       "      <td>125394</td>\n",
       "      <td>0.891000</td>\n",
       "      <td>8.113333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LT Racecar with Noise and Human Boost</td>\n",
       "      <td>172505</td>\n",
       "      <td>153702</td>\n",
       "      <td>0.891000</td>\n",
       "      <td>8.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LT Racecar with No Noise</td>\n",
       "      <td>68643</td>\n",
       "      <td>61161</td>\n",
       "      <td>0.891001</td>\n",
       "      <td>9.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LT Racecar with No Noise and Human Boost</td>\n",
       "      <td>70257</td>\n",
       "      <td>62599</td>\n",
       "      <td>0.891000</td>\n",
       "      <td>9.526667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Car_Type  Total_Episodes  Total_Finishes  \\\n",
       "0                     LT Racecar with Noise          140734          125394   \n",
       "1     LT Racecar with Noise and Human Boost          172505          153702   \n",
       "2                  LT Racecar with No Noise           68643           61161   \n",
       "3  LT Racecar with No Noise and Human Boost           70257           62599   \n",
       "\n",
       "   Final_Victory_Pct  Last_50_Avg_Reward  \n",
       "0           0.891000            8.113333  \n",
       "1           0.891000            8.560000  \n",
       "2           0.891001            9.080000  \n",
       "3           0.891000            9.526667  "
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lt_car_meta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eb248a45c5851c61d411cc68a924ee8e71b7da6271e788b4168c3f15db8ceb03"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
